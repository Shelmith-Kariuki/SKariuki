[{"authors":["admin"],"categories":null,"content":"  body {text-align: justify}  I am a Senior Data Analyst based in Nairobi, Kenya. I am an RStudio Certified Tidyverse trainer, and recently worked as a Research Manager at Geopoll, and as a Data Analyst at Busara Center for Behavioral Economics. I have previously worked as an assistant lecturer in various Kenyan universities, teaching units in Statistics and Actuarial Science. I have a Bsc in Actuarial Science and Msc in Applied Statistics from JKUAT. I have extensive experience in data analysis using R and Python. I co-organize a community of R users in Nairobi #NairobiR and in Africa #AfricaR. One of the missions of my community work is to make sure that we have an increased number of R adopters, in Africa. I am very passionate about training and using data analytics to drive development projects in Africa.\n","date":1554595200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1554595200,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/author/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/","section":"authors","summary":"body {text-align: justify}  I am a Senior Data Analyst based in Nairobi, Kenya. I am an RStudio Certified Tidyverse trainer, and recently worked as a Research Manager at Geopoll, and as a Data Analyst at Busara Center for Behavioral Economics.","tags":null,"title":"","type":"authors"},{"authors":["吳恩達"],"categories":null,"content":"吳恩達 is a professor of artificial intelligence at the Stanford AI Lab. His research interests include distributed robotics, mobile computing and programmable matter. He leads the Robotic Neurobiology group, which develops self-reconfiguring robots, systems of self-organizing robots, and mobile sensor networks.\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Sed neque elit, tristique placerat feugiat ac, facilisis vitae arcu. Proin eget egestas augue. Praesent ut sem nec arcu pellentesque aliquet. Duis dapibus diam vel metus tempus vulputate.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"da99cb196019cc5857b9b3e950397ca9","permalink":"/author/%E5%90%B3%E6%81%A9%E9%81%94/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E5%90%B3%E6%81%A9%E9%81%94/","section":"authors","summary":"吳恩達 is a professor of artificial intelligence at the Stanford AI Lab. His research interests include distributed robotics, mobile computing and programmable matter. He leads the Robotic Neurobiology group, which develops self-reconfiguring robots, systems of self-organizing robots, and mobile sensor networks.","tags":null,"title":"吳恩達","type":"authors"},{"authors":null,"categories":null,"content":"Flexibility This feature can be used for publishing content such as:\n Online courses Project or software documentation Tutorials  The courses folder may be renamed. For example, we can rename it to docs for software/project documentation or tutorials for creating an online course.\nDelete tutorials To remove these pages, delete the courses folder and see below to delete the associated menu link.\nUpdate site menu After renaming or deleting the courses folder, you may wish to update any [[main]] menu links to it by editing your menu configuration at config/_default/menus.toml.\nFor example, if you delete this folder, you can remove the following from your menu configuration:\n[[main]] name = \u0026quot;Courses\u0026quot; url = \u0026quot;courses/\u0026quot; weight = 50  Or, if you are creating a software documentation site, you can rename the courses folder to docs and update the associated Courses menu configuration to:\n[[main]] name = \u0026quot;Docs\u0026quot; url = \u0026quot;docs/\u0026quot; weight = 50  Update the docs menu If you use the docs layout, note that the name of the menu in the front matter should be in the form [menu.X] where X is the folder name. Hence, if you rename the courses/example/ folder, you should also rename the menu definitions in the front matter of files within courses/example/ from [menu.example] to [menu.\u0026lt;NewFolderName\u0026gt;].\n","date":1536451200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1536451200,"objectID":"59c3ce8e202293146a8a934d37a4070b","permalink":"/courses/example/","publishdate":"2018-09-09T00:00:00Z","relpermalink":"/courses/example/","section":"courses","summary":"Learn how to use Academic's docs layout for publishing online courses, software documentation, and tutorials.","tags":null,"title":"Overview","type":"docs"},{"authors":null,"categories":null,"content":"In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\nTip 2 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"74533bae41439377bd30f645c4677a27","permalink":"/courses/example/example1/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/courses/example/example1/","section":"courses","summary":"In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":null,"title":"Example Page 1","type":"docs"},{"authors":null,"categories":null,"content":"Here are some more tips for getting started with Academic:\nTip 3 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\nTip 4 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"1c2b5a11257c768c90d5050637d77d6a","permalink":"/courses/example/example2/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/courses/example/example2/","section":"courses","summary":"Here are some more tips for getting started with Academic:\nTip 3 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":null,"title":"Example Page 2","type":"docs"},{"authors":null,"categories":["workshop","tidyverse","tidymodels"],"content":"  ","date":1595980800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1595980800,"objectID":"392ac6d087a036ce02c55111e9a5ec50","permalink":"/talk/dsa2020/","publishdate":"2020-07-29T00:00:00Z","relpermalink":"/talk/dsa2020/","section":"talk","summary":"  ","tags":null,"title":"Exploring R for Spatial Analytics","type":"talk"},{"authors":null,"categories":["workshop","tidyverse"],"content":"\n\n\n\n","date":1593766800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593766800,"objectID":"8633bc35387e211e0a0c5d2f21dc5905","permalink":"/talk/mir_ggplot2/","publishdate":"2020-07-02T00:00:00Z","relpermalink":"/talk/mir_ggplot2/","section":"talk","summary":"","tags":null,"title":"Getting to know ggplot2","type":"talk"},{"authors":null,"categories":["workshop","tidyverse","rspatial"],"content":"\n\n\n\n","date":1591844400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591844400,"objectID":"9832a41b35b5e8469fea3a878de426b1","permalink":"/talk/wigiske/","publishdate":"2020-06-10T00:00:00Z","relpermalink":"/talk/wigiske/","section":"talk","summary":"","tags":null,"title":"Exploring R for Spatial Analytics","type":"talk"},{"authors":null,"categories":null,"content":"","date":1591574400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591574400,"objectID":"46ffd505f630bd7468d4683b330d3bdf","permalink":"/project/downloadabledata/","publishdate":"2020-06-08T00:00:00Z","relpermalink":"/project/downloadabledata/","section":"project","summary":"The 2019 Kenya and Population Census data can be downloaded from this site.","tags":["R"],"title":"2019 Kenya Census Data ShinyApp","type":"project"},{"authors":null,"categories":null,"content":"","date":1591488000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591488000,"objectID":"e32520564e5717c22dcd438edd319c7a","permalink":"/projectspage/","publishdate":"2020-06-07T00:00:00Z","relpermalink":"/projectspage/","section":"","summary":"This page contains blog posts","tags":null,"title":"Projects","type":"widget_page"},{"authors":null,"categories":null,"content":"","date":1591488000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591488000,"objectID":"e8fe72beed11bd5a9c457620d119e449","permalink":"/talkspage/","publishdate":"2020-06-07T00:00:00Z","relpermalink":"/talkspage/","section":"","summary":"This page contains blog posts","tags":null,"title":"Talks \u0026 Workshops","type":"widget_page"},{"authors":null,"categories":null,"content":"","date":1591056000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591056000,"objectID":"4d71b180930665c4b9a86e9d50f09ee1","permalink":"/blogspage/","publishdate":"2020-06-02T00:00:00Z","relpermalink":"/blogspage/","section":"","summary":"This page contains blog posts","tags":null,"title":"Blog","type":"widget_page"},{"authors":null,"categories":null,"content":"","date":1591056000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591056000,"objectID":"951a66d3a84a91368bcf09c13f5ef687","permalink":"/codework/","publishdate":"2020-06-02T00:00:00Z","relpermalink":"/codework/","section":"","summary":"This page contains codes","tags":null,"title":"Codes","type":"widget_page"},{"authors":null,"categories":null,"content":"","date":1590969600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1590969600,"objectID":"254b3946bd12cd24395b159c73acc45c","permalink":"/contactpage/","publishdate":"2020-06-01T00:00:00Z","relpermalink":"/contactpage/","section":"","summary":"This page contains the contact form","tags":null,"title":"Contact","type":"widget_page"},{"authors":null,"categories":["blog"],"content":" In February 2020, I was lucky to be certified as an RStudio Certified Tidyverse trainer.\nThe certification process was totally amazing. It was led by Greg Wilson who is a member of the RStudio Education team.\nThere are three steps to becoming certified:\n Candidates must take part in a training course on modern teaching methods.\n After completing that course, candidates must complete a 90-minute exam on the material that includes preparing and delivering a 15-minute demonstration lesson.\n Finally, in order to ensure that instructors are proficient with the technical content they will be teaching, they must complete a practical examination and deliver a demonstration for each subject they wish to be certified in.  body {text-align: justify}   Training\nThe training took place on 18th and 19th January, from 8:00 PM to around midnight EAT, on both days. The class comprised of around 12 participants, and 4 instructors.\nA lot of material was covered in those 2 days, but I will only mention a few.\nFirst, I learnt how to distinguish between a novice, a competent student and an expert. As an instructor, you know a novice is learning, when they search for the right things, and can recognize useful answers.\nSecondly, I got to learn about cognitive load. This is the total amount of mental activity imposed on working memory in any one instant. There are three forms of cognitive load. Intrinsic load (this is what people have to keep in mind, in order to absorb new material), germane load (the desirable mental effort required to to link new information to the old information) and extraneous load (anything that distracts learning). As a trainer, one can take care of the mental capacity of students, by chunking i.e dividing your lesson plan into many tiny bits (you would rather have 3 2-hour lessons, than 2 3-hour lessons).\nI also learnt a lot on assessments. There are two kinds of assessments; formative and summative. A formative assessment is one where the trainer uses questions or exercises during the lesson in order to figure out if learning has taken place (think of CATS or RATS), while summative assessment tells you if the learner has mastered the material taught, and is ready to go out on their own (think of the end of semester exam).\nAnother really interesting thing I learnt, was the idea of concept maps. This is a graphical tool that instructional designers use to organize and structure knowledge. I did not study this in school, so it was really new and interesting. Since then, I have used concept maps to guide my teaching, and my work basically. I even had to create a concept map to guide me in writing this blog post.\nYou would think that 4 hours is quite a long time to sit for a session, but it was not the case for these sessions. The instructors encouraged us to take regular 5-10 minutes breaks. They also kept us engaged by asking us to discuss ideas amongst ourselves, and even put some of our thoughts on a google doc (this is such an amazing way to keeping students active during a training session).\nAt the end of the two-day training, we each had to reserve an exam date, on Greg’s calendar. I decided to sit for both exams in about 3 weeks.\nIn those 3 weeks, I prepared adequately. One had to have good knowledge on tidyverse concepts before sitting for the exam, so this was not part of the training. Luckily, I had been using tidyverse since 2017, so I had mastered a majority of the concepts. Nevertheless, I still had to brush through the R for Data Science book , to remind myself of a few things.\nExam\nWhile I was a teaching assistant, I always enjoyed giving exams. Seems I had forgotten how it felt having to sit for one myself.\nThat day, I woke up very very nervous. I did not know what to expect. I spent the day writing these codes, to ensure that I was 100% ready.\nI was to sit for the tidyverse exam from 8:00 PM - 9:30 PM EAT and the teaching exam from 9:30 PM - 11:00 PM EAT.\nThe tidyverse exam was amazing, I loved how it was set. It covered all the tidyverse concepts. I was very very tensed, but the cheerful Greg made the process smooth. I wount lie, there were 2 questions that made me sweat a lot, but luckily, we were allowed to consult Google, when things got thick, and more often than not, Google rarely disappoints. In 90 minutes, I was done.\nI took a 10-15 minutes break, after which I was ready for the teaching exam. The first step involved delivering a 15 minutes lesson to Greg. I chose to teach him some basic dplyr concepts. The next step involved answering a few questions based on the 2 day training we had earlier. This exam also took 90 minutes, so by midnight I was done.\nI received the results 10-15 minutes after completing the teaching exam. That feeling you get when the certificate comes through, is unexplainable. Two days later (on February 14th), I was added to the “wall of fame” (best valentines day ever!! no bouquet of flowers could ever beat that).\nConclusion\nI want to thank my amazing friend, Ahmadou, for encouraging me to go for it. I also want to thank Greg and the entire RStudio Education team for making the process an enjoyable one.\nFore more details about the certification process, please visit this site.\nCheers!!\n","date":1589328000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1589328000,"objectID":"5326e3cec9d11b5f3fee842be3ce6931","permalink":"/post/certification/","publishdate":"2020-05-13T00:00:00Z","relpermalink":"/post/certification/","section":"post","summary":"In February 2020, I was lucky to be certified as an RStudio Certified Tidyverse trainer.\nThe certification process was totally amazing. It was led by Greg Wilson who is a member of the RStudio Education team.","tags":[],"title":"The RStudio Certification Process","type":"post"},{"authors":null,"categories":["blog"],"content":" rKenyaCensus is an R package that contains the 2019 Kenya Population and Housing Census results. The results were released by the Kenya National Bureau of Statistics in February 2020, and published in four different pdf files (Volume 1 - Volume 4).  body {text-align: justify}  These files can be downloaded from the KNBS website.\nThe 2019 Kenya Population and Housing Census was the eighth to be conducted in Kenya since 1948 and was conducted from the night of 24th /25th to 31st August 2019. Kenya leveraged on technology to capture data during cartographic mapping, enumeration and data transmission, making the 2019 Census the first paperless census to be conducted in Kenya (KNBS did a good job 👏, 👏, 👏, 👏).\nThe development version of the package can be installed in R via:\n devtools::install_github(“Shelmith-Kariuki/rKenyaCensus”)  Note: You first have to have devtools installed.\n\nEach table has been scrapped and given a unique identifier, e.g V1.T2.3 is the data in table 2.3 of Volume 1. The DataCatalogue dataset contains a list of the different datasets that are contained in this package. To learn more about each of the different datasets, run ?datasetname, e.g\n?V1_T2.2 This opens up a “Help” page where you can get more information about the dataset, as well as the description of each of the variables.\nA total of 47,564,296 persons were enumerated during the census, comprising 23,548,056 males, 24,014,716 females and 1,524 intersex.\nNote: The idea behind the coord polar graph above was to display the population distribution per County and Gender, ordered by decreasing population size. The bars have only been used to distinguish between male and female proportions.\nThe results indicate a population growth of nine million since the exercise was last carried out 10 years ago.\nNairobi, Nakuru and Kiambu registered the highest population counts.\nMandera, Wajir and Garissa registered the highest average household size, while Nairobi, Kirinyaga and Kiambu registered the least average household size.\nThe process of creating this package was amazing. I used the tabulizer R package to scrap the data from the different pdfs, though I faced a small glitch while trying to scrap two or three of the datasets. For those tables, I used data that had already been scrapped, and was readily available on the internet, even though I had to clean it further. I used the usethis package to “attach” the data onto the package.\nI decided to come up with the package for a host of reasons. To begin with, I believe that people prefer working with data when it is in an “easy to use” format, as opposed to it being in pdf format. The data has been simplified so that data analysts can play around with it, without having to go through the “dirty” process themselves. I am hoping that people can use the data to practise data visualizations, and come up with amazing graphs (or better still, amazing shiny dashboards).\nI have also always wanted to learn package development through a real life project. I am glad that I can now use the usethis::use_data(xxx, overwrite = T) command, and I know what “r cmd-check” is (thanks to Jenny Bryan for creating and maintaining the package). I also needed to work on a project that I could showcase, during my next interview, incase they ask how I spent my time during the Covid19 pandemic (yes, I am job hunting 😿, 😿, 😿, 😿).\nMost of the datasets are exactly as they appear in the pdf files, but for some, I tried manipulating them a little bit so that people could easily use them.\nI also got shapefiles of Kenya County boundaries from a friend (thanks Carole), but unfortunately, I was not able to include them in the package. They can be downloaded from this site. I hope that spatial data analysts could use this data to develop awesome maps (I can’t wait to see what you all come up with 💃, 💃, 💃).\nOne of the major lessons I learnt from the process is that data cleaning is a very very important skill (well, I have always known this, but I am now more convinced). A huge thanks to my friends at the R4DS community, especially Stephen and Scott Came, who came through when I needed help on certain issues.\nI want to appreciate my friends (Tabby, Eric, Nangira, Evelyne, AnnMaureen, Caren and Peter), for taking their time to check the data in the package, against the data in the pdf files. We are confident that this work is error free, but please raise an alarm if you think something is amiss. I also want to thank the amazing John Mutiso, who spent some hours generating some of the amazing graphs that are embedded on this post. Mutiso has been generating awesome #TidyTuesday graphs as well. He was lucky enough to have one of his graphs published in the rweekly.org website (💪, 💪).\nDisclaimer alert: This package is still work in progress. The data is being cleaned and refined on a daily basis. Changes (Volume 3) are being pushed to github every afternoon beginning 29th April, 2020. Please keep refreshing (re-installing) the package, so that you have the most updated version. I am yet to work on Volume 4 of the results. I will post an update once I am done with that.\nUpdate: Volume 4 data is ready, and the package has been updated. Volume 4 includes data showing the distribution of school attendance, work activity (those working vs those job hunting), dominant wall, floor and roofing material of main dwelling units, agricultural data (crops and livestock) for each county, data on different types of disabilities, ownership of mobile phones, usage of the internet, percentage of births that take place in a health facility vs those that take place in a non-health facility, etc.\nThe different datasets can also be downloaded as .csv or .xlsx files, from this shiny app.\nI am also hoping to submit the package to CRAN, once the development version is stable.\nI am happy to discuss further improvements to the package, so please feel free to contact me through the contact form, at the bottom of this site. Again, incase you come across a bug, please do reach out as well, either via the contact form, or better still, open an issue on github.\nParting shot: If you have an amazing idea, start working on it, the end product will satisfy your soul.\nGuess what!! We shall overcome Covid19, but before then, keep safe, stay at home, wash your hands regularly and if you have to leave your premises, please wear a mask. It shall be well.\nStay safe everyone!🇰🇪🇰🇪🇰🇪🇰🇪🇰🇪🇰🇪🇰🇪🇰🇪🇰🇪🇰🇪🇰🇪🇰🇪🇰🇪🇰🇪🇰🇪🇰🇪🇰🇪🇰🇪🇰🇪\n","date":1587945600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1587945600,"objectID":"aa3fabffbcd3f49db3209f7430d98e3d","permalink":"/post/rkenyacensus/","publishdate":"2020-04-27T00:00:00Z","relpermalink":"/post/rkenyacensus/","section":"post","summary":"rKenyaCensus is an R package that contains the 2019 Kenya Population and Housing Census results. The results were released by the Kenya National Bureau of Statistics in February 2020, and published in four different pdf files (Volume 1 - Volume 4).","tags":[],"title":"Introducing rKenyaCensus","type":"post"},{"authors":null,"categories":["blog"],"content":" Coming Soon\n","date":1583832001,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1583832001,"objectID":"d4eac97f6948a34dec93c8b2af988f95","permalink":"/post/amandla/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/post/amandla/","section":"post","summary":"Coming Soon","tags":null,"title":"Amandla...my new baby","type":"post"},{"authors":null,"categories":["workshop","tidyverse"],"content":" Coming Soon\n","date":1582016400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1583832001,"objectID":"7cef70df17fbc1b84f3dc0df0377df57","permalink":"/talk/passa/","publishdate":"2020-03-10T00:00:00Z","relpermalink":"/talk/passa/","section":"talk","summary":"Coming Soon","tags":null,"title":"Kisii University Introduction to Tidyverse","type":"talk"},{"authors":null,"categories":null,"content":" Company_XXX is an online company that meets the growing demand for independent travel information. It offers an extensive hotel meta search to travellers.\nThe following document details results from the ‘Marketing Intelligence’ data task.\nThe task involves two datasets i.e Marketing Campaigns and Session data.\nThe Marketing campaigns data contains weekly information about different online marketing campaigns in one market.\nThe Session data contains information about single visits to the Company_XXX website (= sessions). A click out is logged whenever a user clicks on a hotel and is redirected to the booking page. The booking field is binary and indicates if a hotel booking was logged after one of the click outs.\n\n### 0.1 Install the libraries required ## Create a vector of packages to be installed pkgs \u0026lt;- c(\u0026quot;tidyverse\u0026quot;,\u0026quot;data.table\u0026quot;,\u0026quot;DT\u0026quot;,\u0026quot;lubridate\u0026quot;,\u0026quot;ggthemes\u0026quot;,\u0026quot;randomForest\u0026quot;,\u0026quot;readODS\u0026quot;,\u0026quot;ggcorrplot\u0026quot;) ## Check if there are packages you want to load, that are not already installed. miss_pkgs \u0026lt;- pkgs[!pkgs %in% installed.packages()[,1]] ## Installing the missing packages if(length(miss_pkgs)\u0026gt;0){ install.packages(miss_pkgs) } ## Loading all the packages invisible(lapply(pkgs,library,character.only=TRUE)) ## Remove the objects that are no longer required rm(miss_pkgs) rm(pkgs) \n### Setting the plot theme Company_XXX_theme\u0026lt;- theme_hc()+ theme(legend.position = \u0026quot;right\u0026quot;, legend.direction = \u0026quot;vertical\u0026quot;, #legend.title = element_blank(), plot.title = element_text( size = rel(1.6), hjust = 0.5), plot.subtitle = element_text(size = rel(1.5), hjust = 0.5), #axis.text = element_text( size = rel(1.5)), axis.text.x = element_text(size =rel(1.5),angle = 0), axis.text.y = element_text(size =rel(1.5),angle = 0), axis.title = element_text( size = rel(1.55)), axis.line.x = element_line(size = 1.5, colour = \u0026quot;#c94a38\u0026quot;), panel.background = element_rect(fill = NA)) ### Colours that will be used for the plots Company_XXX_blue = \u0026quot;#377DA9\u0026quot; Company_XXX_maroon = \u0026quot;#BB523A\u0026quot; Company_XXX_yellow = \u0026quot;#E79435\u0026quot; ## Avoidance of scientific numbers options(scipen = 999) ## Printing function pr_func\u0026lt;-function(data,cnames){ datatable(data,colnames = cnames, extensions = \u0026#39;Buttons\u0026#39;, options = list( dom = \u0026#39;Bfrtip\u0026#39;, buttons = c(\u0026#39;copy\u0026#39;, \u0026#39;print\u0026#39;) ) ) } \n### 0.2 Read in the datasets mc_df \u0026lt;- readRDS(\u0026quot;../../../../../PersonalDevelopment/marketing_campaigns2.rds\u0026quot;) sessions_df \u0026lt;- readRDS(\u0026quot;../../../../../PersonalDevelopment/session_data.rds\u0026quot;) Task 1: Marketing Campaigns  Give an overview of entire market’s development and the different campaigns. Please prepare 3-5 charts and summarize the most important findings. See 1.2 - 1.8 below\n How would you assess the development of the quality of traffic, e.g. in terms of revenue per visitor. How is the overall development and how does each campaign evolve? See 1.2 - 1.8 below\n You are talking with the responsible business developer for the market who wants to spend an additional 250€ per week from week 31 onwards. Please help him out with the following questions:\n  What is your advice in which campaign to invest and why? See 1.6 below   How do you expect this to impact the overall performance in the market from week 31 onwards? See 1.6 below   1.1. Clean the dataset, and generate new variables \n ## Convert the Campaign variable to factor mc_df \u0026lt;- mc_df %\u0026gt;% mutate(Campaign = fct_relevel(Campaign,\u0026quot;Aldebaran\u0026quot;,\u0026quot;Bartledan\u0026quot;,\u0026quot;Cottington\u0026quot;)) ## Remove duplicates mc_df \u0026lt;- mc_df %\u0026gt;% unique() ## Generate a profit variable mc_df \u0026lt;- mc_df %\u0026gt;% mutate(Profit = Revenue - Cost) ## Weekly_RPV mc_df \u0026lt;- mc_df %\u0026gt;% mutate(Weekly_RPV = Revenue /Visits)  1.2 Exploring the trend of visits for each of the campaigns \nThe Aldebaran campaign seems to have done really well in terms of attracting visitors to the site, all through the campaign period. As much as the number of visits was quite low in the beginning (as compared to the other two campaigns), and with very few dips in the number of visits here and there, there was a good increasing trend overall.\nThe Bartledan campaign started off at a steady rate, until week 14, where the number of visits to the site picked up a bit till the end.\nThe Cottington campaign maintained a low but steady state in the number of visits all through the campaign period.\ngraph \u0026lt;- mc_df %\u0026gt;% ggplot(aes(x = as.factor(Week), y=Visits, group = Campaign,color = Campaign))+ geom_line(size = 1.1)+ Company_XXX_theme+ scale_color_manual(values = c(Company_XXX_maroon, Company_XXX_yellow, Company_XXX_blue))+ labs(title = \u0026quot;Distribution of the Number of Visits\u0026quot;, x = \u0026quot;Week\u0026quot;, y=\u0026quot;Number of Visits\u0026quot;,color = \u0026quot;Campaign\u0026quot;) graph  1.3 Revenue Per Visitor RPV is the average revenue per visitor to your website.\nHere, we are assuming that a visit represents a unique visitor.\nRPV is calculated by dividing the total income by the number of visitors during a specific time period.\nWe can see that as much the Cottington campaign maintained a low but steady state in the number of visits all through the campaign period (as shown in the previous section), the RPV was the highest, amongst all the three campaigns.\nThis means that the low number of visitors actually generated higher revenue as opposed to the revene that was generated by the higher number of visitors on the other two campaigns.  graph \u0026lt;- mc_df %\u0026gt;% ggplot(aes(x = as.factor(Week), y=Weekly_RPV, group = Campaign,color = Campaign))+ geom_line(size = 1.1)+ Company_XXX_theme+ scale_color_manual(values = c(Company_XXX_maroon, Company_XXX_yellow, Company_XXX_blue))+ labs(title = \u0026quot;Weekly Revenue Per Visitor\u0026quot;, x = \u0026quot;Week\u0026quot;, y=\u0026quot;Revenue Per Visitor\u0026quot;,color = \u0026quot;Campaign\u0026quot;) graph \n ## Generating ROMI RPV_df \u0026lt;- mc_df %\u0026gt;% group_by(Campaign) %\u0026gt;% summarise(RPV = round(sum(Revenue)/ sum(Visits),1)) ## Generate the plot graph \u0026lt;- ggplot(data = RPV_df, mapping = aes(x = Campaign, y = RPV, fill = Campaign))+ geom_bar(stat = \u0026quot;identity\u0026quot;)+ geom_text(aes(label = RPV),vjust = -0.25, size = 5)+ Company_XXX_theme+ scale_fill_manual(values = c(Company_XXX_maroon, Company_XXX_yellow, Company_XXX_blue))+ labs(title = \u0026quot;Overall Revenue Per Visitor\u0026quot;, x = \u0026quot;Campaign\u0026quot;, y=\u0026quot;Revenue Per Visitor\u0026quot;,color = \u0026quot;Campaign\u0026quot;) graph  1.4 Assessing profitability of each of the campaigns over the weeks \nHere, Profit = Revenue - Cost\nIn terms of profitability, the Bartledan campaign was the worst performer as it never generated any profit.\nThe Cottington Campaign was doing well, until Week 20, when it started generating losses.\nCoincidentally, Week 20 is the same week that Aldebaran came out of the red, and started generating profits.\n graph \u0026lt;- mc_df %\u0026gt;% ggplot(aes(x = as.factor(Week), y=Profit, group = Campaign,color = Campaign))+ geom_line(size = 1.1)+ geom_hline(yintercept = 0,color=\u0026quot;black\u0026quot;, linetype = \u0026quot;dashed\u0026quot;)+ geom_vline(xintercept = 20,color=\u0026quot;red\u0026quot;, linetype = \u0026quot;dashed\u0026quot;)+ Company_XXX_theme+ scale_color_manual(values = c(Company_XXX_maroon, Company_XXX_yellow, Company_XXX_blue))+ labs(title = \u0026quot;Assessing Weekly Campaign Profitability\u0026quot;, x = \u0026quot;Week\u0026quot;, y=\u0026quot;Profitability\u0026quot;,color = \u0026quot;Campaign\u0026quot;) graph  1.5 Assessing Overall Campaign Profitability \nThroughout the campaign period, the Cottington campaign is the only one that made a significant amount of profit.  abs_df \u0026lt;- mc_df %\u0026gt;% select(Week, Campaign, Revenue, Cost) %\u0026gt;% pivot_longer(cols = Revenue:Cost, names_to =\u0026quot;Revenue_Cost\u0026quot; ,values_to = \u0026quot;Value\u0026quot;) %\u0026gt;% group_by(Campaign,Revenue_Cost) %\u0026gt;% summarise(Value = round(sum(Value),1)) ## Generate the plot graph \u0026lt;- ggplot(data = abs_df, mapping = aes(x = Campaign, y = Value, fill = Revenue_Cost))+ geom_bar(stat = \u0026quot;identity\u0026quot;, position = \u0026quot;dodge\u0026quot;)+ geom_text(aes(label = Value),vjust = -0.25, size = 5, position = position_dodge(width = 1))+ Company_XXX_theme+ scale_fill_manual(values = c(\u0026quot;#377DA9\u0026quot;,\u0026quot;#E79435\u0026quot;))+ labs(title = \u0026quot;Assessing Overall Campaign Profitability\u0026quot;, x = \u0026quot;Campaign\u0026quot;, y=\u0026quot;Revenue/Cost\u0026quot;,color = \u0026quot;Measure\u0026quot;) graph  1.6 Return on Marketing Investment (ROMI) ROMI is an indication of return on investment in marketing.\nROMI = [Total sales - marketing campaign costs / marketing campaign costs] There is a larger ROMI on the Cottington campaign, as compared to the Aldebaran campaign. The Bartledan resulted into a negative ROMI, even though the number of visits to the site kept on increasing, as the weeks flew by.\nI would advise the business developer for the market to invest in the Cotington Campaign. This is because as much as the campaign generally attracts a smaller number of visitors, as compared to the other campaigns, the ROMI is high, and the Revenue per Visitor is also high.\n ## Generating ROMI ROMI_df \u0026lt;- mc_df %\u0026gt;% group_by(Campaign) %\u0026gt;% summarise(ROMI_abs = (sum(Revenue)-sum(Cost)) / sum(Cost), ROMI_perc = round(ROMI_abs * 100,2)) ## Generate the plot graph \u0026lt;- ggplot(data = ROMI_df, mapping = aes(x = Campaign, y = ROMI_perc, fill = Campaign))+ geom_bar(stat = \u0026quot;identity\u0026quot;)+ geom_text(aes(label = ROMI_perc),vjust = -0.25, size = 5)+ Company_XXX_theme+ scale_fill_manual(values = c(Company_XXX_maroon, Company_XXX_yellow, Company_XXX_blue))+ labs(title = \u0026quot;Assessing Campaign Profitability \\n (ROMI)\u0026quot;, x = \u0026quot;Campaign\u0026quot;, y=\u0026quot;ROMI (%)\u0026quot;,color = \u0026quot;Campaign\u0026quot;)+ ylim(-15,5) graph  1.7 Does the type of campaign predict profit? Company_XXX is likely to obtain a significant profit of 11.2 for an additional investment on the Cottington campaign, as opposed to the investment being made on the Aldebaran campaign.\nCompany_XXX would make a huge loss (27.6) if it invested cash on the Bartledan campaign.\nmodel1 \u0026lt;- lm(Profit ~ Campaign, data = mc_df) summary(model1) Call: lm(formula = Profit ~ Campaign, data = mc_df) Residuals: Min 1Q Median 3Q Max -56.473 -9.864 1.269 14.199 46.555 Coefficients: Estimate Std. Error t value Pr(\u0026gt;|t|) (Intercept) 0.9631 3.6803 0.262 0.7942 CampaignBartledan -27.5866 5.2047 -5.300 0.000000864 *** CampaignCottington 11.2372 5.2047 2.159 0.0336 * --- Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1 Residual standard error: 20.16 on 87 degrees of freedom Multiple R-squared: 0.4038, Adjusted R-squared: 0.3901 F-statistic: 29.47 on 2 and 87 DF, p-value: 0.0000000001693  ## Generating a tidy table model1_tidy \u0026lt;- broom::tidy(model1) basevalues \u0026lt;- c(\u0026quot;CampaignAldebaran\u0026quot;,0, 5.204708, 0, 0) model1_tidy \u0026lt;- rbind(model1_tidy,basevalues) model1_tidy$term \u0026lt;- gsub(\u0026quot;Campaign\u0026quot;,\u0026quot;\u0026quot;,model1_tidy$term) model1_tidy \u0026lt;- model1_tidy%\u0026gt;% filter(term !=\u0026quot;(Intercept)\u0026quot;) model1_tidy \u0026lt;- model1_tidy%\u0026gt;% mutate(estimate = round(as.numeric(estimate),1)) model1_tidy \u0026lt;- model1_tidy%\u0026gt;% rename(Campaign = term) #model1_tidy$estimate \u0026lt;- round(model1_tidy$estimate) ## Generate the plot graph \u0026lt;- ggplot(data = model1_tidy, mapping = aes(x = Campaign, y = estimate, fill = Campaign))+ geom_bar(stat = \u0026quot;identity\u0026quot;)+ geom_text(aes(label = estimate),vjust = -0.25, size = 5)+ Company_XXX_theme+ scale_fill_manual(values = c(Company_XXX_maroon, Company_XXX_yellow, Company_XXX_blue))+ labs(title = \u0026quot;Profit ~ Campaign\u0026quot;, x = \u0026quot;Campaign\u0026quot;, y=\u0026quot;Regression Estimate\u0026quot;,color = \u0026quot;Campaign\u0026quot;)+ ylim(-30,13) graph  1.8 Does the type of campaign predict number of visits? model2 \u0026lt;- lm(Visits ~ Campaign, data = mc_df) summary(model2) Call: lm(formula = Visits ~ Campaign, data = mc_df) Residuals: Min 1Q Median 3Q Max -293.667 -33.933 0.233 20.067 292.333 Coefficients: Estimate Std. Error t value Pr(\u0026gt;|t|) (Intercept) 320.67 19.14 16.752 \u0026lt; 0.0000000000000002 *** CampaignBartledan -147.73 27.07 -5.457 0.0000004493 *** CampaignCottington -169.90 27.07 -6.276 0.0000000131 *** --- Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1 Residual standard error: 104.8 on 87 degrees of freedom Multiple R-squared: 0.3486, Adjusted R-squared: 0.3336 F-statistic: 23.28 on 2 and 87 DF, p-value: 0.000000007978  ## Generating a tidy table model2_tidy \u0026lt;- broom::tidy(model2) basevalues \u0026lt;- c(\u0026quot;CampaignAldebaran\u0026quot;,0, 5.204708, 0, 0) model2_tidy \u0026lt;- rbind(model2_tidy,basevalues) model2_tidy$term \u0026lt;- gsub(\u0026quot;Campaign\u0026quot;,\u0026quot;\u0026quot;,model2_tidy$term) model2_tidy \u0026lt;- model2_tidy%\u0026gt;% filter(term !=\u0026quot;(Intercept)\u0026quot;) model2_tidy \u0026lt;- model2_tidy%\u0026gt;% mutate(estimate = round(as.numeric(estimate),1)) model2_tidy \u0026lt;- model2_tidy%\u0026gt;% rename(Campaign = term) #model2_tidy$estimate \u0026lt;- round(model2_tidy$estimate) ## Generate the plot graph \u0026lt;- ggplot(data = model2_tidy, mapping = aes(x = Campaign, y = estimate, fill = Campaign))+ geom_bar(stat = \u0026quot;identity\u0026quot;)+ geom_text(aes(label = estimate),vjust = -0.25, size = 5)+ Company_XXX_theme+ scale_fill_manual(values = c(Company_XXX_maroon, Company_XXX_yellow, Company_XXX_blue))+ labs(title = \u0026quot;Number of Visits ~ Campaign\u0026quot;, x = \u0026quot;Campaign\u0026quot;, y=\u0026quot;Regression Estimate\u0026quot;,color = \u0026quot;Campaign\u0026quot;) graph   Task 2: Session data Test to see if there are any connections between the booking data and any other given information.\n2.1 Create additional variables \nduration: the length of time taken on the session\nstart_hour: the hour when the session started.\ntime_of_day: the time of day i.e Early Morning, Morning, Afternoon, Evening ## Session duration sessions_df \u0026lt;- sessions_df%\u0026gt;% mutate(duration = difftime(session_end_text, session_start_text, units = \u0026quot;secs\u0026quot;,tz = \u0026quot;EAT\u0026quot;), duration = ifelse(duration \u0026lt;0, (24*60*60)+duration, duration)) ## Start hour sessions_df \u0026lt;- sessions_df%\u0026gt;% mutate(start_hour = hour(session_start_text)) ## hour_of_day sessions_df \u0026lt;- sessions_df %\u0026gt;% mutate(start_hour = as.numeric(start_hour)) %\u0026gt;% mutate(time_of_day = ifelse(start_hour \u0026gt;=0 \u0026amp; start_hour \u0026lt;=5,\u0026quot;Early Morning\u0026quot;, ifelse(start_hour \u0026gt;=6 \u0026amp; start_hour \u0026lt;=11,\u0026quot;Morning\u0026quot;, ifelse(start_hour \u0026gt;=12 \u0026amp; start_hour \u0026lt;=18,\u0026quot;Afternoon\u0026quot;, ifelse(start_hour \u0026gt;=19 \u0026amp; start_hour \u0026lt;=23,\u0026quot;Evening\u0026quot;,\u0026quot;\u0026quot;)))))  2.2 Is there a difference in means of booking, between the different times of day? H0: The mean of the booking variable, for all the different times = 0\nHa: At least one of the means is not 0\nThe P-value is very large (\u0026gt;0.05) meaning that the means are not really different from each other, and that this variable is not predictive of the instance of booking.  ## Generate anova results anova_test \u0026lt;- aov(booking ~ time_of_day, data = sessions_df) summary(anova_test) Df Sum Sq Mean Sq F value Pr(\u0026gt;F) time_of_day 3 0.1 0.03623 0.415 0.742 Residuals 9996 873.4 0.08737 TukeyHSD(anova_test) Tukey multiple comparisons of means 95% family-wise confidence level Fit: aov(formula = booking ~ time_of_day, data = sessions_df) $time_of_day diff lwr upr p adj Early Morning-Afternoon 0.001126106 -0.01967051 0.02192273 0.9990396 Evening-Afternoon 0.007688625 -0.01407098 0.02944823 0.8006404 Morning-Afternoon 0.006476426 -0.01419107 0.02714393 0.8520366 Evening-Early Morning 0.006562519 -0.01597362 0.02909866 0.8774553 Morning-Early Morning 0.005350320 -0.01613322 0.02683386 0.9190753 Morning-Evening -0.001212199 -0.02362924 0.02120484 0.9990434  2.3 What is the correlation between the continuous variables? There is no correlation between the ‘booking variable’ and any othe variables. Meaning none of the variables can predict booking. ## Generate the correlation matrix corr_mat \u0026lt;- cor(sessions_df %\u0026gt;% select(booking, clickouts, duration, start_hour)) corr_mat booking clickouts duration start_hour booking 1.0000000000 -0.049811677 0.01044032 0.0009995598 clickouts -0.0498116772 1.000000000 0.03979617 -0.0077694714 duration 0.0104403163 0.039796170 1.00000000 0.0154922952 start_hour 0.0009995598 -0.007769471 0.01549230 1.0000000000 \n ## Generate the p-values of this correlation matrix p.mat \u0026lt;- cor_pmat(corr_mat) p.mat booking clickouts duration start_hour booking 0.0000000 0.5628733 0.6811493 0.6836681 clickouts 0.5628733 0.0000000 0.7530925 0.6518106 duration 0.6811493 0.7530925 0.0000000 0.6746880 start_hour 0.6836681 0.6518106 0.6746880 0.0000000 ## Generate the correlation plot. ggcorrplot(corr_mat, outline.col = \u0026quot;white\u0026quot;,lab = TRUE, ggtheme = Company_XXX_theme, colors = c(Company_XXX_maroon, Company_XXX_yellow, Company_XXX_blue), title = \u0026quot;Correlation Plot\u0026quot;)   ","date":1579824000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1579824000,"objectID":"cfe60b944200e87d64b16c49287670fb","permalink":"/project/mi/","publishdate":"2020-01-24T00:00:00Z","relpermalink":"/project/mi/","section":"project","summary":"Company_XXX is an online company that meets the growing demand for independent travel information. It offers an extensive hotel meta search to travellers.\nThe following document details results from the ‘Marketing Intelligence’ data task.","tags":["R"],"title":"Marketing Intelligence","type":"project"},{"authors":null,"categories":["R"],"content":" There are 5 ways (that I know of) in which we can factorise multiple variables in R.\n One by one (an option for beginners). Using a for loop. lapply() forcats::fct_relevel() purrr::map()  0. Load the packages that we will require \n## Create a vector of packages that we will need pkgs \u0026lt;- c(\u0026quot;dplyr\u0026quot;,\u0026quot;purrr\u0026quot;,\u0026quot;repurrrsive\u0026quot;) ## Check if there are variables you want to load, that are not already installed. miss_pkgs \u0026lt;- pkgs[!pkgs %in% installed.packages()[,1]] ## Installing the missing packages if(length(miss_pkgs)\u0026gt;0){ install.packages(miss_pkgs) } ## Loading all the packages invisible(lapply(pkgs,library,character.only=TRUE)) ## Remove the objects that are no longer required rm(miss_pkgs) rm(pkgs) Assuming you have a matrix type question (where respondents were asked to rate the questions on a scale of 1 - 5, where 1 represents Strongly Disagree and 5 represents Strongly Agree). set.seed(2020) vec \u0026lt;- 1:5 Questions \u0026lt;- paste0(\u0026quot;Opinion_\u0026quot;,vec) opinion_df \u0026lt;- data.frame(matrix(\u0026quot;\u0026quot;, ncol=5, nrow=200)) names(opinion_df) \u0026lt;- Questions for(i in 1: length(Questions)){ opinion_df[,Questions[i]] \u0026lt;- sample(c(\u0026quot;Strongly Agree\u0026quot;, \u0026quot;Agree\u0026quot;,\u0026quot;Neutral\u0026quot;,\u0026quot;Disagree\u0026quot;, \u0026quot;Strongly Disagree\u0026quot;),size = 200,replace = TRUE) } head(opinion_df, 10) ## Opinion_1 Opinion_2 Opinion_3 Opinion_4 ## 1 Disagree Disagree Agree Disagree ## 2 Disagree Agree Agree Strongly Disagree ## 3 Strongly Agree Neutral Strongly Agree Neutral ## 4 Strongly Agree Strongly Disagree Agree Neutral ## 5 Disagree Neutral Agree Strongly Agree ## 6 Agree Neutral Neutral Neutral ## 7 Strongly Agree Neutral Strongly Disagree Strongly Agree ## 8 Strongly Disagree Neutral Neutral Strongly Agree ## 9 Agree Disagree Strongly Agree Agree ## 10 Agree Disagree Agree Neutral ## Opinion_5 ## 1 Agree ## 2 Disagree ## 3 Neutral ## 4 Neutral ## 5 Disagree ## 6 Disagree ## 7 Strongly Disagree ## 8 Neutral ## 9 Agree ## 10 Disagree  1. Factorizing one by one \nopinion_df2 \u0026lt;- opinion_df ## Opinion_1 opinion_df2$Opinion_1 \u0026lt;- factor(opinion_df2$Opinion_1, levels = c(\u0026quot;Strongly Disagree\u0026quot;, \u0026quot;Disagree\u0026quot;,\u0026quot;Neutral\u0026quot;,\u0026quot;Agree\u0026quot;, \u0026quot;Strongly Agree\u0026quot;), labels = c(\u0026quot;Strongly Disagree\u0026quot;, \u0026quot;Disagree\u0026quot;,\u0026quot;Neutral\u0026quot;,\u0026quot;Agree\u0026quot;, \u0026quot;Strongly Agree\u0026quot;)) ## Opinion_2 opinion_df2$Opinion_2 \u0026lt;- factor(opinion_df2$Opinion_2, levels = c(\u0026quot;Strongly Disagree\u0026quot;, \u0026quot;Disagree\u0026quot;,\u0026quot;Neutral\u0026quot;,\u0026quot;Agree\u0026quot;, \u0026quot;Strongly Agree\u0026quot;), labels = c(\u0026quot;Strongly Disagree\u0026quot;, \u0026quot;Disagree\u0026quot;,\u0026quot;Neutral\u0026quot;,\u0026quot;Agree\u0026quot;, \u0026quot;Strongly Agree\u0026quot;)) ## Sorry, I cannot continue with this replication  2. Using a for loop \nopinion_df3 \u0026lt;- opinion_df factor_function \u0026lt;- function(data,var){ data[,var] \u0026lt;- factor(data[,var], levels = c(\u0026quot;Strongly Disagree\u0026quot;, \u0026quot;Disagree\u0026quot;,\u0026quot;Neutral\u0026quot;,\u0026quot;Agree\u0026quot;, \u0026quot;Strongly Agree\u0026quot;), labels = c(\u0026quot;Strongly Disagree\u0026quot;, \u0026quot;Disagree\u0026quot;,\u0026quot;Neutral\u0026quot;,\u0026quot;Agree\u0026quot;, \u0026quot;Strongly Agree\u0026quot;)) return(data[,var]) } for( i in 1:length(Questions)){ opinion_df3[,Questions[i]] \u0026lt;- factor_function(opinion_df3,Questions[i]) print(levels(opinion_df3[,Questions[i]])) } ## [1] \u0026quot;Strongly Disagree\u0026quot; \u0026quot;Disagree\u0026quot; \u0026quot;Neutral\u0026quot; ## [4] \u0026quot;Agree\u0026quot; \u0026quot;Strongly Agree\u0026quot; ## [1] \u0026quot;Strongly Disagree\u0026quot; \u0026quot;Disagree\u0026quot; \u0026quot;Neutral\u0026quot; ## [4] \u0026quot;Agree\u0026quot; \u0026quot;Strongly Agree\u0026quot; ## [1] \u0026quot;Strongly Disagree\u0026quot; \u0026quot;Disagree\u0026quot; \u0026quot;Neutral\u0026quot; ## [4] \u0026quot;Agree\u0026quot; \u0026quot;Strongly Agree\u0026quot; ## [1] \u0026quot;Strongly Disagree\u0026quot; \u0026quot;Disagree\u0026quot; \u0026quot;Neutral\u0026quot; ## [4] \u0026quot;Agree\u0026quot; \u0026quot;Strongly Agree\u0026quot; ## [1] \u0026quot;Strongly Disagree\u0026quot; \u0026quot;Disagree\u0026quot; \u0026quot;Neutral\u0026quot; ## [4] \u0026quot;Agree\u0026quot; \u0026quot;Strongly Agree\u0026quot;  3. Using lapply(). sapply() is kind of usually moody at times, and this was one of those days. So I used lapply(), and it works. opinion_df \u0026lt;- data.frame(opinion_df) opinion_df4 \u0026lt;- as.data.frame(lapply(opinion_df, function(x) factor(x, levels = c(\u0026quot;Strongly Disagree\u0026quot;, \u0026quot;Disagree\u0026quot;,\u0026quot;Neutral\u0026quot;,\u0026quot;Agree\u0026quot;, \u0026quot;Strongly Agree\u0026quot;), labels = c(\u0026quot;Strongly Disagree\u0026quot;, \u0026quot;Disagree\u0026quot;,\u0026quot;Neutral\u0026quot;,\u0026quot;Agree\u0026quot;, \u0026quot;Strongly Agree\u0026quot;))),check.names = FALSE) levels(opinion_df3$Opinion_4) ## [1] \u0026quot;Strongly Disagree\u0026quot; \u0026quot;Disagree\u0026quot; \u0026quot;Neutral\u0026quot; ## [4] \u0026quot;Agree\u0026quot; \u0026quot;Strongly Agree\u0026quot;  4. Using forcats::fct_relevel() \nopinion_df5 \u0026lt;- opinion_df %\u0026gt;% dplyr::mutate_all(forcats::fct_relevel, \u0026quot;Strongly Disagree\u0026quot;, \u0026quot;Disagree\u0026quot;, \u0026quot;Neutral\u0026quot;, \u0026quot;Agree\u0026quot;, \u0026quot;Strongly Agree\u0026quot;) levels(opinion_df5$Opinion_4) ## [1] \u0026quot;Strongly Disagree\u0026quot; \u0026quot;Disagree\u0026quot; \u0026quot;Neutral\u0026quot; ## [4] \u0026quot;Agree\u0026quot; \u0026quot;Strongly Agree\u0026quot;  5. Using purrr::map() \nThe syntax is written as map(.x,.f) i.e for each element of .x, do .f opinion_df6 \u0026lt;-bind_rows(map(opinion_df, ~factor(.x, levels = c(\u0026quot;Strongly Disagree\u0026quot;, \u0026quot;Disagree\u0026quot;,\u0026quot;Neutral\u0026quot;,\u0026quot;Agree\u0026quot;, \u0026quot;Strongly Agree\u0026quot;), labels = c(\u0026quot;Strongly Disagree\u0026quot;, \u0026quot;Disagree\u0026quot;,\u0026quot;Neutral\u0026quot;,\u0026quot;Agree\u0026quot;, \u0026quot;Strongly Agree\u0026quot;)))) levels(opinion_df6$Opinion_4) ## [1] \u0026quot;Strongly Disagree\u0026quot; \u0026quot;Disagree\u0026quot; \u0026quot;Neutral\u0026quot; ## [4] \u0026quot;Agree\u0026quot; \u0026quot;Strongly Agree\u0026quot;  ","date":1579046400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1579046400,"objectID":"6ec13ba1919cc450f7a43f0e6736c1a1","permalink":"/codes/factorvariables/factoringvariables/","publishdate":"2020-01-15T00:00:00Z","relpermalink":"/codes/factorvariables/factoringvariables/","section":"codes","summary":"There are 5 ways (that I know of) in which we can factorise multiple variables in R.\n One by one (an option for beginners). Using a for loop. lapply() forcats::fct_relevel() purrr::map()  0.","tags":["R Markdown"],"title":"Factorizing variables in R","type":"codes"},{"authors":null,"categories":["R"],"content":"    Example 1    Consider 20 first year resident female doctors drawn at random from one area, resting systolic blood pressures measured using an electronic gadget were:\n128, 118, 144, 133, 132, 111, 149, 139,136,126, 127,115,142, 140, 131,132,122,119,129,128.\nFrom previous large studies of women drawn at random from the healthy general public, a resting systolic blood pressure of 120mm was predicted as the population mean, for the relevant age group. Test to see whether there is a difference between the means at 95% level of significance. \n Calculations by hand  knitr::include_graphics(\u0026quot;/img/DSC06212_2.jpg\u0026quot;)  Execution in R  ## load the library required to intergrate R and Python library(reticulate)  ## Load the python libraries from scipy.stats import ttest_1samp #used for carrying out one sample t-tests ## Generate a vector of values vals \u0026lt;- c(128, 118, 144, 133, 132, 111, 149, 139,136,126, 127,115,142, 140, 131,132,122,119,129,128) ## Carry out the t-test to determine whether the population mean is significantly different from 120 t.test(vals, mu=120,alternative = \u0026quot;two.sided\u0026quot;)  One Sample t-test data: vals t = 4.5124, df = 19, p-value = 0.0002384 alternative hypothesis: true mean is not equal to 120 95 percent confidence interval: 125.3884 134.7116 sample estimates: mean of x 130.05   Execution in Python   ## Generate a vector of values vals_py = [128, 118, 144, 133, 132, 111, 149, 139,136,126, 127,115,142, 140, 131,132,122,119,129,128] ## Carry out the t-test to determine whether the population mean is significantly different from 120 ttest_1samp(vals_py, 120)  Ttest_1sampResult(statistic=4.512403659336718, pvalue=0.00023838063630967753)    Example 2     Calculations by hand  knitr::include_graphics(\u0026quot;/img/DSC06213.JPG\u0026quot;) knitr::include_graphics(\u0026quot;/img/DSC06214.JPG\u0026quot;)  Execution in R  ## Generate a vector of values volume \u0026lt;- c(484.11,459.49,471.38,512.01,494.48,528.63,493.64,485.03,473.88, 501.59,502.85,538.08,465.68,495.03,475.32,529.41,518.13,464.32,449.08,489.27) ## Carry out the t-test t.test(volume, alternative = \u0026quot;less\u0026quot;, mu=500,conf.level = 0.99)  One Sample t-test data: volume t = -1.5205, df = 19, p-value = 0.07243 alternative hypothesis: true mean is less than 500 99 percent confidence interval: -Inf 505.6495 sample estimates: mean of x 491.5705   Execution in Python  ## Generate a vector of values volume = [484.11,459.49,471.38,512.01,494.48,528.63,493.64,485.03,473.88, 501.59,502.85,538.08,465.68,495.03,475.32,529.41,518.13,464.32,449.08,489.27] ## Carry out the t-test ttest_1samp(volume, 500) ##Notes: ## The p-value obtained is that of a two tailed test, so we divide it by 2 to get the p-value of a one tailed test (0.14486225283259022/2 = 0.07243113) Ttest_1sampResult(statistic=-1.5204626102079255, pvalue=0.14486225283259022) ","date":1566172800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1566172800,"objectID":"128335635288cd9dd673bfb429ff334f","permalink":"/codes/ttests/t-tests/","publishdate":"2019-08-19T00:00:00Z","relpermalink":"/codes/ttests/t-tests/","section":"codes","summary":"Example 1    Consider 20 first year resident female doctors drawn at random from one area, resting systolic blood pressures measured using an electronic gadget were:","tags":["R Markdown"],"title":"One sample t-tests","type":"codes"},{"authors":null,"categories":null,"content":"           Company_XXX is an online company that meets the growing demand for independent travel information. it offers an extensive hotel meta search to travellers.\nCompany_XXX hosts different case studies on their website, that job applicants can work on.\nTask: The task consists of user visit data, stored as a csv. First, we would like you to perform some descriptive analysis of the data at hand. What can you tell us about the visits that are included? Imagine that you want to understand our product and think about what would be important for you. Explore the data, get a feel for how it is structured and show us what you can do. Some topics you may want to look into are:\nWhat is good for the product, what is bad? + Anomalies in data + Inferences from the data\nSecondly define three KPI’s for the performance of the product and show how they are calculated. Describe what you see and try to think about why these developments might be happening. Define plausible reasons for any changes you might observe in the data.\n## Install the libraries required ## create a vector of packages to be installed pkgs \u0026lt;- c(\u0026quot;tidyverse\u0026quot;,\u0026quot;data.table\u0026quot;,\u0026quot;DT\u0026quot;,\u0026quot;lubridate\u0026quot;,\u0026quot;ggthemes\u0026quot;) ## Check if there are packages you want to load, that are not already installed. miss_pkgs \u0026lt;- pkgs[!pkgs %in% installed.packages()[,1]] ## Installing the missing packages if(length(miss_pkgs)\u0026gt;0){ install.packages(miss_pkgs) } ## Loading all the packages invisible(lapply(pkgs,library,character.only=TRUE)) ## Remove the objects that are no longer required rm(miss_pkgs) rm(pkgs) \n### Setting the plot theme Company_XXX_theme\u0026lt;- theme_hc()+ theme(legend.position = \u0026quot;right\u0026quot;, legend.direction = \u0026quot;vertical\u0026quot;, #legend.title = element_blank(), plot.title = element_text( size = rel(1.6), hjust = 0.5), plot.subtitle = element_text(size = rel(1.5), hjust = 0.5), #axis.text = element_text( size = rel(1.5)), axis.text.x = element_text(size =rel(1.5),angle = 0), axis.text.y = element_text(size =rel(1.5),angle = 0), axis.title = element_text( size = rel(1.55)), axis.line.x = element_line(size = 1.5, colour = \u0026quot;#c94a38\u0026quot;), panel.background = element_rect(fill = NA)) ### Colours that will be used for the plots Company_XXX_blue = \u0026quot;#007faf\u0026quot; Company_XXX_orange = \u0026quot;#c94a38\u0026quot; Company_XXX_yellow = \u0026quot;#f48f00\u0026quot; ## Avoidance of scientific numbers options(scipen = 999) ## Printing function pr_func\u0026lt;-function(data,cnames){ datatable(data,colnames = cnames, extensions = \u0026#39;Buttons\u0026#39;, options = list( dom = \u0026#39;Bfrtip\u0026#39;, buttons = c(\u0026#39;copy\u0026#39;, \u0026#39;print\u0026#39;) ) ) }  ## Read in the datasets page_log \u0026lt;- read_csv(\u0026quot;../../../../../PersonalDevelopment/page_log.csv\u0026quot;) visit_caseStudy \u0026lt;- read_delim(\u0026quot;../../../../../PersonalDevelopment/visit_caseStudy.csv\u0026quot;,\u0026quot;;\u0026quot;, escape_double = FALSE, trim_ws = TRUE) Task 1 The first part of the challenge involved analysis of user visit data.\nThe data provided is only one day’s worth, as is shown by the minimum timestamp, i.e 2018-06-13 and maximum timestamp, i.e 2018-06-13 23:59:59\nThe data contains 142599 unique participants, and a total of 156638 unique sessions, meaning on average 1.1 sessions per user.\nThe analysis sought to answer the following questions:\n On average, how many times did users visit the website?\n Of those who visited the website only once, how many made successive bookings?\n Of those who visited the website more than once, what was the rate of successful bookings?\n Where are most of the website users based?\n Is there a trend in website visit times? Do users prefer visiting the website in the morning, afternoon or evening?\n Generally, what is the length of time between the booking date and start of travel date?\n What is the distribution of advertisers\n Which advertiser results into a majority of booking errors?\n For those who only visit the website once and never succeed in booking, how far along is the travel date from the booking date? Is it that they do not log in again because the trip is not that urgent?\n For those who visited the website more than once, what is the average length of time between the first visit and second visit?\n For those who re-visit the website within one hour, after how many minutes do they do so?\n For those who visited the website more than once and were not successful in making a booking in the first instance, after how many trials (sessions) were they successful?\n  1. On average, how many times did users visit the website? From the plot given below, a majority of the users (94%) visited the website only once. I would be keen to find out whether they made successive bookings.\nNote: The graph has been truncated to only display information for those who visited the website less than 7 times\n\n ## Table summ_tab \u0026lt;- visit_caseStudy %\u0026gt;% distinct(tracking_id, session_id) %\u0026gt;% group_by(tracking_id) %\u0026gt;% summarise(frequency = n()) %\u0026gt;% ungroup() %\u0026gt;% group_by(frequency) %\u0026gt;% summarise(count = n()) %\u0026gt;% mutate(perc = round((count/sum(count))*100,0)) ## Print the table pr_func(summ_tab,cnames = c(\u0026quot;Number of Log-Ins\u0026quot;,\u0026quot;Frequency\u0026quot;,\u0026quot;Percentage\u0026quot;) )  {\"x\":{\"filter\":\"none\",\"extensions\":[\"Buttons\"],\"data\":[[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\"],[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,20,30],[133815,6107,1448,673,253,147,60,33,20,13,10,4,4,1,1,2,2,2,2,2],[94,4,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]],\"container\":\"\\n \\n \\n  \\n Number of Log-Ins\\n Frequency\\n Percentage\\n \\n \\n\",\"options\":{\"dom\":\"Bfrtip\",\"buttons\":[\"copy\",\"print\"],\"columnDefs\":[{\"className\":\"dt-right\",\"targets\":[1,2,3]},{\"orderable\":false,\"targets\":0}],\"order\":[],\"autoWidth\":false,\"orderClasses\":false}},\"evals\":[],\"jsHooks\":[]}  ## Graph summ_graph \u0026lt;- ggplot(summ_tab%\u0026gt;% filter(frequency \u0026lt;6), aes(x=frequency,y=count))+ geom_bar(stat = \u0026quot;identity\u0026quot;, fill=Company_XXX_yellow)+ geom_text(aes(label =count),vjust = -0.25, size = 5)+ Company_XXX_theme+ labs(title = \u0026quot;Distribution of Website Visits\u0026quot;,x=\u0026quot;Number of Log-Ins\u0026quot;, y=\u0026quot;Frequency\u0026quot;) summ_graph  2. Of those who visited the website only once, how many made successive bookings? A majority (98%) of those who only visited the website once did not succeed in making a booking.\n\n## Table summ_tab \u0026lt;- visit_caseStudy %\u0026gt;% distinct(tracking_id, session_id,.keep_all = TRUE) %\u0026gt;% group_by(tracking_id) %\u0026gt;% mutate(frequency = n()) %\u0026gt;% filter(frequency==1) %\u0026gt;% ungroup() %\u0026gt;% mutate(bookingOk = ifelse(bookingOk==0,\u0026quot;No\u0026quot;,\u0026quot;Yes\u0026quot;)) %\u0026gt;% group_by(bookingOk) %\u0026gt;% summarise(count = n()) %\u0026gt;% mutate(perc = round((count/sum(count))*100,0)) ## Print the table pr_func(summ_tab,cnames = c(\u0026quot;Ok Booking\u0026quot;,\u0026quot;Frequency\u0026quot;,\u0026quot;Percentage\u0026quot;) )  {\"x\":{\"filter\":\"none\",\"extensions\":[\"Buttons\"],\"data\":[[\"1\",\"2\"],[\"No\",\"Yes\"],[131560,2255],[98,2]],\"container\":\"\\n \\n \\n  \\n Ok Booking\\n Frequency\\n Percentage\\n \\n \\n\",\"options\":{\"dom\":\"Bfrtip\",\"buttons\":[\"copy\",\"print\"],\"columnDefs\":[{\"className\":\"dt-right\",\"targets\":[2,3]},{\"orderable\":false,\"targets\":0}],\"order\":[],\"autoWidth\":false,\"orderClasses\":false}},\"evals\":[],\"jsHooks\":[]}  ## Graph summ_graph \u0026lt;- ggplot(summ_tab, aes(x=bookingOk,y=count,fill=bookingOk))+ geom_bar(stat = \u0026quot;identity\u0026quot;)+ geom_text(aes(label =count),vjust = -0.25, size = 5)+ Company_XXX_theme+ scale_fill_manual(values = c(Company_XXX_yellow, Company_XXX_blue))+ labs(title = \u0026quot;Distribution of Successive Bookings\u0026quot;,x=\u0026quot;\u0026quot;, y=\u0026quot;Frequency\u0026quot;) summ_graph  3. Of those who visited the website more than once, what was the rate of successful bookings? \nsumm_tab \u0026lt;- visit_caseStudy %\u0026gt;% distinct(tracking_id, session_id,.keep_all = TRUE) %\u0026gt;% group_by(tracking_id) %\u0026gt;% mutate(frequency = n()) %\u0026gt;% filter(frequency!=1) %\u0026gt;% ungroup() %\u0026gt;% mutate(bookingOk = ifelse(bookingOk==0,\u0026quot;No\u0026quot;,\u0026quot;Yes\u0026quot;)) %\u0026gt;% group_by(frequency,bookingOk) %\u0026gt;% summarise(count = n()) %\u0026gt;% mutate(perc = round((count/sum(count))*100,0)) ## Print the table pr_func(summ_tab,cnames = c(\u0026quot;Number of Log-Ins\u0026quot;,\u0026quot;Ok Booking\u0026quot;,\u0026quot;Frequency\u0026quot;,\u0026quot;Percentage\u0026quot;) )  {\"x\":{\"filter\":\"none\",\"extensions\":[\"Buttons\"],\"data\":[[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\",\"21\",\"22\",\"23\",\"24\",\"25\",\"26\",\"27\",\"28\",\"29\",\"30\",\"31\",\"32\",\"33\",\"34\"],[2,2,3,3,4,4,5,5,6,6,7,7,8,8,9,9,10,10,11,11,12,13,13,14,15,16,16,17,17,18,20,20,30,30],[\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\",\"No\",\"No\",\"Yes\",\"No\",\"Yes\"],[11954,260,4269,75,2657,35,1250,15,876,6,417,3,258,6,176,4,125,5,109,1,48,51,1,14,15,31,1,32,2,36,39,1,59,1],[98,2,98,2,99,1,99,1,99,1,99,1,98,2,98,2,96,4,99,1,100,98,2,100,100,97,3,94,6,100,98,2,98,2]],\"container\":\"\\n \\n \\n  \\n Number of Log-Ins\\n Ok Booking\\n Frequency\\n Percentage\\n \\n \\n\",\"options\":{\"dom\":\"Bfrtip\",\"buttons\":[\"copy\",\"print\"],\"columnDefs\":[{\"className\":\"dt-right\",\"targets\":[1,3,4]},{\"orderable\":false,\"targets\":0}],\"order\":[],\"autoWidth\":false,\"orderClasses\":false}},\"evals\":[],\"jsHooks\":[]}  ## Graph summ_graph \u0026lt;- ggplot(summ_tab%\u0026gt;% filter(frequency \u0026lt;6), aes(x=frequency,y=count,color=bookingOk))+ geom_line(stat = \u0026quot;identity\u0026quot;)+ #geom_text(aes(label =count),vjust = -0.25, size = 5)+ Company_XXX_theme+ scale_color_manual(values = c(Company_XXX_yellow, Company_XXX_blue))+ labs(title = \u0026quot;Distribution of Bookings\u0026quot;,x=\u0026quot;\u0026quot;, y=\u0026quot;Frequency\u0026quot;) summ_graph  4. Where are most of the website users based? A majority of the website users are based in US, followed by IT. summ_tab \u0026lt;- visit_caseStudy %\u0026gt;% distinct(tracking_id, session_id,.keep_all = TRUE) %\u0026gt;% group_by(locale) %\u0026gt;% summarise(count = n()) %\u0026gt;% arrange(desc(count)) %\u0026gt;% mutate(perc = round((count/sum(count))*100,0)) ## Print the table pr_func(summ_tab,cnames = c(\u0026quot;Locale\u0026quot;,\u0026quot;Frequency\u0026quot;,\u0026quot;Percentage\u0026quot;) )  {\"x\":{\"filter\":\"none\",\"extensions\":[\"Buttons\"],\"data\":[[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\",\"21\",\"22\",\"23\",\"24\",\"25\",\"26\",\"27\",\"28\",\"29\",\"30\",\"31\",\"32\",\"33\",\"34\",\"35\",\"36\",\"37\",\"38\",\"39\",\"40\",\"41\",\"42\",\"43\",\"44\",\"45\"],[\"US\",\"IT\",\"DE\",\"ES\",\"FR\",\"GB\",\"MX\",\"GR\",\"PT\",\"PL\",\"AU\",\"TR\",\"NL\",\"NZ\",\"CA\",\"BE\",\"AT\",\"BR\",\"RU\",\"CH\",\"AR\",\"SE\",\"IE\",\"IN\",\"FI\",\"DK\",\"NO\",\"CL\",\"CO\",\"RO\",\"AE\",\"ZA\",\"CZ\",\"MY\",\"PH\",\"UY\",\"HK\",\"PE\",\"SG\",\"EC\",\"TH\",\"AA\",null,\"ID\",\"EN\"],[17472,17417,16478,14681,12388,11990,11132,8123,6107,4999,4712,4634,4297,2793,2599,2486,1606,1510,1406,1228,1090,1055,815,802,706,643,468,460,430,334,305,266,243,228,170,123,108,103,83,77,36,33,8,2,1],[11,11,11,9,8,8,7,5,4,3,3,3,3,2,2,2,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]],\"container\":\"\\n \\n \\n  \\n Locale\\n Frequency\\n Percentage\\n \\n \\n\",\"options\":{\"dom\":\"Bfrtip\",\"buttons\":[\"copy\",\"print\"],\"columnDefs\":[{\"className\":\"dt-right\",\"targets\":[2,3]},{\"orderable\":false,\"targets\":0}],\"order\":[],\"autoWidth\":false,\"orderClasses\":false}},\"evals\":[],\"jsHooks\":[]}  ## Graph summ_graph \u0026lt;- ggplot(summ_tab %\u0026gt;% filter(count\u0026gt;5000), aes(x=locale,y=count))+ geom_bar(stat = \u0026quot;identity\u0026quot;,fill = Company_XXX_yellow)+ geom_text(aes(label =count),vjust = -0.25, size = 5)+ Company_XXX_theme+ labs(title = \u0026quot;Distribution of Users \\nby\\n Locaion\u0026quot;,x=\u0026quot;Hour\u0026quot;, y=\u0026quot;Frequency\u0026quot;) summ_graph  5. Is there a trend in website visit times? Do users prefer visiting the website in the morning, afternoon or evening? A majority of users visit the website in the afternoon. summ_tab \u0026lt;- visit_caseStudy %\u0026gt;% mutate(hour = hour(date)) %\u0026gt;% distinct(tracking_id, session_id,.keep_all = TRUE) %\u0026gt;% group_by(hour) %\u0026gt;% summarise(frequency = length(unique(session_id))) ## Print the table pr_func(summ_tab,cnames = c(\u0026quot;Hour\u0026quot;,\u0026quot;Frequency\u0026quot;) )  {\"x\":{\"filter\":\"none\",\"extensions\":[\"Buttons\"],\"data\":[[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\",\"21\",\"22\",\"23\",\"24\"],[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23],[3607,2862,2774,2721,2645,2992,3780,4939,6100,6957,7059,7269,7558,8348,8575,9321,9678,9898,9790,9994,9662,8686,6571,4853]],\"container\":\"\\n \\n \\n  \\n Hour\\n Frequency\\n \\n \\n\",\"options\":{\"dom\":\"Bfrtip\",\"buttons\":[\"copy\",\"print\"],\"columnDefs\":[{\"className\":\"dt-right\",\"targets\":[1,2]},{\"orderable\":false,\"targets\":0}],\"order\":[],\"autoWidth\":false,\"orderClasses\":false}},\"evals\":[],\"jsHooks\":[]}  ## Graph summ_graph \u0026lt;- ggplot(summ_tab, aes(x=hour,y=frequency,group=1, color=1))+ geom_line(stat = \u0026quot;identity\u0026quot;,color = Company_XXX_yellow)+ #geom_text(aes(label =count),vjust = -0.25, size = 5)+ Company_XXX_theme+ labs(title = \u0026quot;Distribution of Website Visits \\n by \\n Time of Day \u0026quot;,x=\u0026quot;Hour\u0026quot;, y=\u0026quot;Frequency\u0026quot;) summ_graph  6. Generally, what is the length of time between the booking date and start of travel date? A majority of users tend to make bookings a few days to the actual travel date.  summ_tab \u0026lt;- visit_caseStudy %\u0026gt;% distinct(tracking_id, session_id,.keep_all = TRUE) %\u0026gt;% mutate(bookingOk = ifelse(bookingOk==0,\u0026quot;No\u0026quot;,\u0026quot;Yes\u0026quot;)) %\u0026gt;% group_by(tracking_id) %\u0026gt;% mutate(frequency = n()) %\u0026gt;% mutate(diff_days = difftime(travelStartDate, as.Date(date), units=\u0026quot;days\u0026quot;)) %\u0026gt;% group_by(diff_days)%\u0026gt;% summarise(count = n()) ## Graph summ_graph \u0026lt;- ggplot(summ_tab, aes(x=diff_days,y=count,group=1, color=1))+ geom_line(stat = \u0026quot;identity\u0026quot;,color = Company_XXX_yellow)+ #geom_text(aes(label =count),vjust = -0.25, size = 5)+ Company_XXX_theme+ labs(title = \u0026quot;Length of time \\n beween \\n Booking Date and Travel Start Date \u0026quot;,x=\u0026quot;Length (days)\u0026quot;,y=\u0026quot;Frequency\u0026quot;)+ylim(c(0,6000))+xlim(c(0,200)) summ_graph  7. Distribution of advertisers A majority of the website site clicks are on advertisers D7A8, followed by CEFA. summ_tab \u0026lt;- visit_caseStudy %\u0026gt;% distinct(tracking_id, session_id,.keep_all = TRUE) %\u0026gt;% group_by(advertiser) %\u0026gt;% summarise(count = n()) ## Print the table pr_func(summ_tab,cnames = c(\u0026quot;Advertiser\u0026quot;,\u0026quot;Frequency\u0026quot;))  {\"x\":{\"filter\":\"none\",\"extensions\":[\"Buttons\"],\"data\":[[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\",\"21\",\"22\",\"23\",\"24\",\"25\",\"26\",\"27\",\"28\",\"29\",\"30\",\"31\",\"32\",\"33\",\"34\",\"35\",\"36\",\"37\",\"38\",\"39\",\"40\",\"41\",\"42\",\"43\",\"44\",\"45\",\"46\",\"47\",\"48\",\"49\",\"50\",\"51\",\"52\",\"53\",\"54\",\"55\",\"56\",\"57\",\"58\",\"59\",\"60\",\"61\",\"62\",\"63\",\"64\",\"65\",\"66\",\"67\",\"68\",\"69\",\"70\",\"71\",\"72\",\"73\"],[\"0233\",\"0266\",\"077E\",\"0FF3\",\"11D0\",\"19F3\",\"1CD1\",\"20D1\",\"2491\",\"28B6\",\"2A50\",\"2CBC\",\"2F4F\",\"33E7\",\"3614\",\"3953\",\"3C94\",\"3CEC\",\"3D86\",\"4E0C\",\"4EBC\",\"5055\",\"539F\",\"555D\",\"5938\",\"5A14\",\"5FA9\",\"6244\",\"6403\",\"6E62\",\"6EA2\",\"7180\",\"71E0\",\"735B\",\"78F7\",\"81B3\",\"852C\",\"884C\",\"8BD3\",\"8C30\",\"8CB2\",\"8E82\",\"9431\",\"952C\",\"9B04\",\"A29D\",\"A6EA\",\"A784\",\"AB23\",\"AD71\",\"B1A5\",\"B7A7\",\"B9D4\",\"BE53\",\"C429\",\"C59B\",\"CBB6\",\"CEFA\",\"CFA0\",\"CFCD\",\"D7A8\",\"D89F\",\"D964\",\"DB9E\",\"DCF6\",\"E165\",\"EDA8\",\"EE8F\",\"F3D9\",\"F473\",\"F61D\",\"F708\",\"FE13\"],[4860,5501,242,82,6,2527,3127,200,2863,8,2330,1134,2259,3,630,54,8,2016,3827,906,1299,47,5765,833,354,2571,1,2824,90,98,36,552,44,662,1856,195,1437,8,16,29,12436,2646,2,205,134,1,243,1697,4,15770,360,198,4739,167,2,3595,32,16881,468,8,22822,5,196,970,2365,1614,3537,440,59,12863,107,724,57]],\"container\":\"\\n \\n \\n  \\n Advertiser\\n Frequency\\n \\n \\n\",\"options\":{\"dom\":\"Bfrtip\",\"buttons\":[\"copy\",\"print\"],\"columnDefs\":[{\"className\":\"dt-right\",\"targets\":2},{\"orderable\":false,\"targets\":0}],\"order\":[],\"autoWidth\":false,\"orderClasses\":false}},\"evals\":[],\"jsHooks\":[]}  ## Graph summ_graph \u0026lt;- ggplot(summ_tab %\u0026gt;%filter(count\u0026gt;5000), aes(x=advertiser,y=count))+ geom_bar(stat = \u0026quot;identity\u0026quot;,fill = Company_XXX_yellow)+ geom_text(aes(label =count),vjust = -0.25, size = 5)+ Company_XXX_theme+ labs(title = \u0026quot;Distribution of advertisers\u0026quot;,x=\u0026quot;Advertisers\u0026quot;, y=\u0026quot;Frequency\u0026quot;) summ_graph  8. Which advertiser results into a majority of booking errors The top 5 advertisers that result into booking errors are 539F, 555D, 5A14,78F7 and 8E82.\n\nsumm_tab \u0026lt;- visit_caseStudy %\u0026gt;% distinct(tracking_id, session_id,.keep_all = TRUE) %\u0026gt;% group_by(advertiser) %\u0026gt;% summarise(count = n(), sum_errors = round(sum(bookingError!=0)/count*1000,1), sum_oks = round(sum(bookingOk!=0)/count*1000,1)) ## Print the table pr_func(summ_tab,cnames = c(\u0026quot;Advertiser\u0026quot;,\u0026quot;Frequency\u0026quot;,\u0026quot;Error Rate\u0026quot;,\u0026quot;Success Rate\u0026quot;))  {\"x\":{\"filter\":\"none\",\"extensions\":[\"Buttons\"],\"data\":[[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\",\"21\",\"22\",\"23\",\"24\",\"25\",\"26\",\"27\",\"28\",\"29\",\"30\",\"31\",\"32\",\"33\",\"34\",\"35\",\"36\",\"37\",\"38\",\"39\",\"40\",\"41\",\"42\",\"43\",\"44\",\"45\",\"46\",\"47\",\"48\",\"49\",\"50\",\"51\",\"52\",\"53\",\"54\",\"55\",\"56\",\"57\",\"58\",\"59\",\"60\",\"61\",\"62\",\"63\",\"64\",\"65\",\"66\",\"67\",\"68\",\"69\",\"70\",\"71\",\"72\",\"73\"],[\"0233\",\"0266\",\"077E\",\"0FF3\",\"11D0\",\"19F3\",\"1CD1\",\"20D1\",\"2491\",\"28B6\",\"2A50\",\"2CBC\",\"2F4F\",\"33E7\",\"3614\",\"3953\",\"3C94\",\"3CEC\",\"3D86\",\"4E0C\",\"4EBC\",\"5055\",\"539F\",\"555D\",\"5938\",\"5A14\",\"5FA9\",\"6244\",\"6403\",\"6E62\",\"6EA2\",\"7180\",\"71E0\",\"735B\",\"78F7\",\"81B3\",\"852C\",\"884C\",\"8BD3\",\"8C30\",\"8CB2\",\"8E82\",\"9431\",\"952C\",\"9B04\",\"A29D\",\"A6EA\",\"A784\",\"AB23\",\"AD71\",\"B1A5\",\"B7A7\",\"B9D4\",\"BE53\",\"C429\",\"C59B\",\"CBB6\",\"CEFA\",\"CFA0\",\"CFCD\",\"D7A8\",\"D89F\",\"D964\",\"DB9E\",\"DCF6\",\"E165\",\"EDA8\",\"EE8F\",\"F3D9\",\"F473\",\"F61D\",\"F708\",\"FE13\"],[4860,5501,242,82,6,2527,3127,200,2863,8,2330,1134,2259,3,630,54,8,2016,3827,906,1299,47,5765,833,354,2571,1,2824,90,98,36,552,44,662,1856,195,1437,8,16,29,12436,2646,2,205,134,1,243,1697,4,15770,360,198,4739,167,2,3595,32,16881,468,8,22822,5,196,970,2365,1614,3537,440,59,12863,107,724,57],[2.9,6.2,0,0,0,2.4,7.7,0,0.3,0,4.7,0.9,8.4,0,3.2,0,0,2,1.8,7.7,0.8,0,17.7,16.8,0,13.6,0,5.3,0,0,0,0,0,1.5,10.2,0,2.1,0,0,0,2.7,10.2,0,0,0,0,0,1.2,0,6.8,2.8,0,0.4,0,0,2.2,0,1.7,0,0,6.4,0,0,0,0.4,3.1,9.3,0,0,4.5,0,1.4,0],[8.2,25.8,8.3,12.2,0,28.5,10.2,0,25.1,0,26.6,7.1,12.4,0,30.2,18.5,0,23.3,6.3,8.8,2.3,42.6,42.8,38.4,8.5,15.9,0,11.3,44.4,0,27.8,1.8,45.5,9.1,11.3,25.6,11.8,0,0,0,10.5,27.6,0,24.4,7.5,0,4.1,5.3,0,10.5,36.1,0,9.1,6,0,9.5,31.2,24.5,8.5,0,12.9,0,15.3,9.3,14,29.1,18.9,6.8,0,26,9.3,9.7,35.1]],\"container\":\"\\n \\n \\n  \\n Advertiser\\n Frequency\\n Error Rate\\n Success Rate\\n \\n \\n\",\"options\":{\"dom\":\"Bfrtip\",\"buttons\":[\"copy\",\"print\"],\"columnDefs\":[{\"className\":\"dt-right\",\"targets\":[2,3,4]},{\"orderable\":false,\"targets\":0}],\"order\":[],\"autoWidth\":false,\"orderClasses\":false}},\"evals\":[],\"jsHooks\":[]}  ## Graph summ_graph \u0026lt;- ggplot(summ_tab %\u0026gt;%filter(sum_errors\u0026gt;5), aes(x=advertiser,y=sum_errors,group=1))+ geom_line(stat = \u0026quot;identity\u0026quot;,color = Company_XXX_yellow)+ geom_text(aes(label =sum_errors),vjust = -0.25, size = 5,color = Company_XXX_blue)+ Company_XXX_theme+ labs(title = \u0026quot;Booking Error Rates\u0026quot;,x=\u0026quot;Advertisers\u0026quot;, y=\u0026quot;Booking error rate (in 000s)\u0026quot;) summ_graph  ## Graph summ_graph2 \u0026lt;- ggplot(summ_tab %\u0026gt;%filter(sum_oks\u0026gt;25), aes(x=advertiser,y=sum_oks,group=1))+ geom_line(stat = \u0026quot;identity\u0026quot;,color = Company_XXX_yellow)+ geom_text(aes(label =sum_oks),vjust = -0.25, size = 5,color = Company_XXX_blue)+ Company_XXX_theme+ labs(title = \u0026quot;Booking Success Rates\u0026quot;,x=\u0026quot;Advertisers\u0026quot;, y=\u0026quot;Booking success rate (in 000s)\u0026quot;) summ_graph2  9. For those who only visit the website once and never succeed in booking, how far along is the travel date from the booking date? Is it that they do not log in again because the trip is not that urgent? A majority of users will mostly visit the website when their travel date is a few days away from the booking date.\n\n summ_tab \u0026lt;- visit_caseStudy %\u0026gt;% distinct(tracking_id, session_id,.keep_all = TRUE) %\u0026gt;% mutate(bookingOk = ifelse(bookingOk==0,\u0026quot;No\u0026quot;,\u0026quot;Yes\u0026quot;)) %\u0026gt;% group_by(tracking_id) %\u0026gt;% mutate(frequency = n()) %\u0026gt;% filter(frequency==1 \u0026amp; bookingOk !=\u0026quot;Yes\u0026quot;) %\u0026gt;% mutate(diff_days = difftime(travelStartDate, as.Date(date), units=\u0026quot;days\u0026quot;)) %\u0026gt;% group_by(diff_days)%\u0026gt;% summarise(count = n()) ## Graph summ_graph \u0026lt;- ggplot(summ_tab, aes(x=diff_days,y=count,group=1, color=1))+ geom_line(stat = \u0026quot;identity\u0026quot;,color = Company_XXX_yellow)+ #geom_text(aes(label =count),vjust = -0.25, size = 5)+ Company_XXX_theme+ labs(title = \u0026quot;Length of time \\n beween \\nBooking Date and Travel Start Date \u0026quot;,x=\u0026quot;Length (days)\u0026quot;,y=\u0026quot;Frequency\u0026quot;)+ylim(c(0,6000))+xlim(c(0,200)) summ_graph  10. For those who visited the website more than once, what is the average length of time between the first visit and second visit? A majority of them revisit the website in an hour’s time.\n summ_tab \u0026lt;- visit_caseStudy %\u0026gt;% distinct(tracking_id, session_id,.keep_all = TRUE) %\u0026gt;% mutate(bookingOk = ifelse(bookingOk==0,\u0026quot;No\u0026quot;,\u0026quot;Yes\u0026quot;)) %\u0026gt;% group_by(tracking_id) %\u0026gt;% mutate(frequency = n()) %\u0026gt;% filter(frequency \u0026gt;1) %\u0026gt;% group_by(tracking_id) %\u0026gt;% arrange(date) %\u0026gt;% mutate(diff_hours = zoo::na.locf0(round(difftime(lead(date), date, units=\u0026quot;hours\u0026quot;),0)))%\u0026gt;% distinct(tracking_id, diff_hours) %\u0026gt;% mutate(seq = seq_along(tracking_id)) %\u0026gt;% filter(seq == 1) %\u0026gt;% ungroup() %\u0026gt;% group_by(diff_hours) %\u0026gt;% summarise(count = n())%\u0026gt;% mutate(perc = round((count/sum(count))*100,0)) %\u0026gt;% ungroup() %\u0026gt;% mutate(diff_hours = as.factor(diff_hours)) ## Print the table pr_func(summ_tab,cnames = c(\u0026quot;Difference in time (hours)\u0026quot;,\u0026quot;Frequency\u0026quot;,\u0026quot;Percentage\u0026quot;))  {\"x\":{\"filter\":\"none\",\"extensions\":[\"Buttons\"],\"data\":[[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\",\"21\",\"22\",\"23\",\"24\",\"25\"],[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\",\"21\",\"22\",\"23\",\"24\"],[4079,1189,688,517,405,305,231,233,193,187,142,105,115,81,71,45,56,28,21,24,22,18,16,12,1],[46,14,8,6,5,3,3,3,2,2,2,1,1,1,1,1,1,0,0,0,0,0,0,0,0]],\"container\":\"\\n \\n \\n  \\n Difference in time (hours)\\n Frequency\\n Percentage\\n \\n \\n\",\"options\":{\"dom\":\"Bfrtip\",\"buttons\":[\"copy\",\"print\"],\"columnDefs\":[{\"className\":\"dt-right\",\"targets\":[2,3]},{\"orderable\":false,\"targets\":0}],\"order\":[],\"autoWidth\":false,\"orderClasses\":false}},\"evals\":[],\"jsHooks\":[]}  ## Graph summ_graph \u0026lt;- ggplot(summ_tab %\u0026gt;%filter(perc\u0026gt;3), aes(x=diff_hours,y=perc))+ geom_bar(stat = \u0026quot;identity\u0026quot;,fill = Company_XXX_yellow)+ geom_text(aes(label =perc),vjust = -0.25, size = 5)+ Company_XXX_theme+ labs(title = \u0026quot;\u0026quot;,x=\u0026quot;Difference in time (hours)\u0026quot;, y=\u0026quot;Percentage\u0026quot;) summ_graph  11. For those who re-visit the website within one hour, after how many minutes do they do so? A majority of them revisit the website within the same minute.  summ_tab \u0026lt;- visit_caseStudy %\u0026gt;% distinct(tracking_id, session_id,.keep_all = TRUE) %\u0026gt;% mutate(bookingOk = ifelse(bookingOk==0,\u0026quot;No\u0026quot;,\u0026quot;Yes\u0026quot;)) %\u0026gt;% group_by(tracking_id) %\u0026gt;% mutate(frequency = n()) %\u0026gt;% filter(frequency \u0026gt;1) %\u0026gt;% group_by(tracking_id) %\u0026gt;% arrange(date) %\u0026gt;% mutate(diff_hours = zoo::na.locf0(round(difftime(lead(date), date, units=\u0026quot;hours\u0026quot;),0)), diff_mins = zoo::na.locf0(round(difftime(lead(date), date, units=\u0026quot;min\u0026quot;),0)))%\u0026gt;% distinct(tracking_id, diff_hours,diff_mins) %\u0026gt;% mutate(seq = seq_along(tracking_id)) %\u0026gt;% filter(seq == 1) %\u0026gt;% filter(diff_hours == 0) %\u0026gt;% ungroup() %\u0026gt;% group_by(diff_mins) %\u0026gt;% summarise(count = n())%\u0026gt;% mutate(perc = round((count/sum(count))*100,0)) %\u0026gt;% ungroup() %\u0026gt;% mutate(diff_mins = as.factor(diff_mins)) ## Print the table pr_func(summ_tab,cnames = c(\u0026quot;Difference in time (mins)\u0026quot;,\u0026quot;Frequency\u0026quot;,\u0026quot;Percentage\u0026quot;))  {\"x\":{\"filter\":\"none\",\"extensions\":[\"Buttons\"],\"data\":[[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\",\"21\",\"22\",\"23\",\"24\",\"25\",\"26\",\"27\",\"28\",\"29\",\"30\",\"31\"],[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\",\"21\",\"22\",\"23\",\"24\",\"25\",\"26\",\"27\",\"28\",\"29\",\"30\"],[936,638,389,260,207,155,136,118,103,97,80,65,83,64,52,59,52,52,46,50,49,52,37,35,43,46,50,38,35,36,16],[23,16,10,6,5,4,3,3,3,2,2,2,2,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0]],\"container\":\"\\n \\n \\n  \\n Difference in time (mins)\\n Frequency\\n Percentage\\n \\n \\n\",\"options\":{\"dom\":\"Bfrtip\",\"buttons\":[\"copy\",\"print\"],\"columnDefs\":[{\"className\":\"dt-right\",\"targets\":[2,3]},{\"orderable\":false,\"targets\":0}],\"order\":[],\"autoWidth\":false,\"orderClasses\":false}},\"evals\":[],\"jsHooks\":[]}  ## Graph summ_graph \u0026lt;- ggplot(summ_tab %\u0026gt;%filter(perc\u0026gt;3), aes(x=diff_mins,y=perc))+ geom_bar(stat = \u0026quot;identity\u0026quot;,fill = Company_XXX_yellow)+ geom_text(aes(label =perc),vjust = -0.25, size = 5)+ Company_XXX_theme+ labs(title = \u0026quot;\u0026quot;,x=\u0026quot;Difference in time (mins)\u0026quot;, y=\u0026quot;Percentage\u0026quot;) summ_graph  12. For those who visited the website more than once and were not successful in making a booking in the first instance, after how many trials (sessions) were they successful? \nA majority of the users succeed in making a booking after the second trial.\n summ_tab \u0026lt;- visit_caseStudy %\u0026gt;% distinct(tracking_id, session_id,.keep_all = TRUE) %\u0026gt;% mutate(bookingOk = ifelse(bookingOk==0,\u0026quot;No\u0026quot;,\u0026quot;Yes\u0026quot;)) %\u0026gt;% group_by(tracking_id) %\u0026gt;% mutate(frequency = n()) %\u0026gt;% filter(frequency \u0026gt;1) %\u0026gt;% group_by(tracking_id) %\u0026gt;% arrange(date) %\u0026gt;% distinct(tracking_id, session_id, bookingPriceTotal) %\u0026gt;% mutate(seq = seq_along(bookingPriceTotal)) %\u0026gt;% mutate(Trials = ifelse(sum(bookingPriceTotal)==0,0,NA)) %\u0026gt;% mutate(Trials = ifelse(bookingPriceTotal!=0,seq,Trials)) %\u0026gt;% arrange(tracking_id) %\u0026gt;% distinct(tracking_id, Trials) %\u0026gt;% filter(!is.na(Trials)) %\u0026gt;% distinct(tracking_id, .keep_all = T) %\u0026gt;% ungroup() %\u0026gt;% group_by(Trials) %\u0026gt;% summarise(count = n())%\u0026gt;% mutate(perc = round((count/sum(count))*100,0)) ## Print the table pr_func(summ_tab,cnames = c(\u0026quot;Number of trials\u0026quot;,\u0026quot;Frequency\u0026quot;,\u0026quot;Percentage\u0026quot;))  {\"x\":{\"filter\":\"none\",\"extensions\":[\"Buttons\"],\"data\":[[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\"],[0,1,2,3,4,5,6,7,8,9,10,11,16,19,29],[8381,129,180,46,21,8,7,2,4,1,1,1,1,1,1],[95,1,2,1,0,0,0,0,0,0,0,0,0,0,0]],\"container\":\"\\n \\n \\n  \\n Number of trials\\n Frequency\\n Percentage\\n \\n \\n\",\"options\":{\"dom\":\"Bfrtip\",\"buttons\":[\"copy\",\"print\"],\"columnDefs\":[{\"className\":\"dt-right\",\"targets\":[1,2,3]},{\"orderable\":false,\"targets\":0}],\"order\":[],\"autoWidth\":false,\"orderClasses\":false}},\"evals\":[],\"jsHooks\":[]}  ## Graph summ_graph \u0026lt;- ggplot(summ_tab %\u0026gt;%filter(count\u0026lt;200), aes(x=Trials,y=count))+ geom_bar(stat = \u0026quot;identity\u0026quot;,fill = Company_XXX_yellow)+ geom_text(aes(label =count),vjust = -0.25, size = 5)+ Company_XXX_theme+ labs(title = \u0026quot;Number of Trials before Successful Bookings\u0026quot;,x=\u0026quot;Number of Trials\u0026quot;, y=\u0026quot;Frequency\u0026quot;) summ_graph   Task 2 The second part of the challenge involved a dataset showing list of actions, of the users in part 1. Each row in the data corresponds to a logged event\nThe questions I sought to answer in this task include:\n What actions are common? Can we think how this relates to the Company_XXX Express Booking?\n What are the most common final actions for a user? Why is that?\n How are actions distributed and can we infer anything from that?\n What might be the action that we consider as a conversion? Is there a feasible way to verify that?\n  1. What actions are common? Can we think how this relates to the Company_XXX Express Booking? \n ## Generate a dataset that only contains the page_log_id, tracking_id, session_id and page_id task2_data \u0026lt;-page_log %\u0026gt;% distinct(page_log_id, tracking_id, session_id, page_id) A majority of the respondents spend most of their time on Page 9020 and Page 9005.\n\n## Calculate the number of page_log ids for each user and each page summ_tab \u0026lt;- task2_data %\u0026gt;% group_by(tracking_id, session_id,page_id) %\u0026gt;% summarise(counter = length(unique(page_log_id))) %\u0026gt;% group_by(page_id) %\u0026gt;% summarise(avg_logins = round(mean(counter),1)) %\u0026gt;% ungroup() %\u0026gt;% mutate(page_id = as.factor(page_id)) ## Print the table pr_func(summ_tab,cnames = c(\u0026quot;Page_ID\u0026quot;,\u0026quot;Average number of Page_log_IDs\u0026quot;))  {\"x\":{\"filter\":\"none\",\"extensions\":[\"Buttons\"],\"data\":[[\"1\",\"2\",\"3\",\"4\",\"5\"],[\"9003\",\"9005\",\"9006\",\"9007\",\"9020\"],[1.4,6,2.5,1.6,5.1]],\"container\":\"\\n \\n \\n  \\n Page_ID\\n Average number of Page_log_IDs\\n \\n \\n\",\"options\":{\"dom\":\"Bfrtip\",\"buttons\":[\"copy\",\"print\"],\"columnDefs\":[{\"className\":\"dt-right\",\"targets\":2},{\"orderable\":false,\"targets\":0}],\"order\":[],\"autoWidth\":false,\"orderClasses\":false}},\"evals\":[],\"jsHooks\":[]}  ## Graph summ_graph \u0026lt;- ggplot(summ_tab, aes(x=page_id,y=avg_logins))+ geom_bar(stat = \u0026quot;identity\u0026quot;,fill = Company_XXX_yellow)+ geom_text(aes(label =avg_logins),vjust = -0.25, size = 5)+ Company_XXX_theme+ labs(title = \u0026quot;Average number of Page_log_IDs\\n per \\n Page ID\u0026quot;,x=\u0026quot;Page ID\u0026quot;, y=\u0026quot;Average\u0026quot;) summ_graph  2. What are the most common final actions for a user? Why is that? \nA majority of sessions end on Page ID 9020.\n summ_tab \u0026lt;- page_log %\u0026gt;% group_by(tracking_id, session_id) %\u0026gt;% arrange(date) %\u0026gt;% mutate(seq= seq_along(session_id)) %\u0026gt;% filter(seq == max(seq)) %\u0026gt;% group_by(page_id) %\u0026gt;% summarise(count = length(unique(session_id)))%\u0026gt;% mutate(page_id = as.factor(page_id))%\u0026gt;% mutate(perc = round((count/sum(count))*100,0)) ## Print the table pr_func(summ_tab,cnames = c(\u0026quot;Page_ID\u0026quot;,\u0026quot;Frequency\u0026quot;,\u0026quot;Percentage\u0026quot;))  {\"x\":{\"filter\":\"none\",\"extensions\":[\"Buttons\"],\"data\":[[\"1\",\"2\",\"3\",\"4\",\"5\"],[\"9003\",\"9005\",\"9006\",\"9007\",\"9020\"],[9131,16288,33,2445,125095],[6,11,0,2,82]],\"container\":\"\\n \\n \\n  \\n Page_ID\\n Frequency\\n Percentage\\n \\n \\n\",\"options\":{\"dom\":\"Bfrtip\",\"buttons\":[\"copy\",\"print\"],\"columnDefs\":[{\"className\":\"dt-right\",\"targets\":[2,3]},{\"orderable\":false,\"targets\":0}],\"order\":[],\"autoWidth\":false,\"orderClasses\":false}},\"evals\":[],\"jsHooks\":[]}  ## Graph summ_graph \u0026lt;- ggplot(summ_tab, aes(x=page_id,y=count))+ geom_bar(stat = \u0026quot;identity\u0026quot;,fill = Company_XXX_yellow)+ geom_text(aes(label =count),vjust = -0.25, size = 5)+ Company_XXX_theme+ labs(title = \u0026quot;Number of session ends\\n per \\n Page ID\u0026quot;,x=\u0026quot;Page ID\u0026quot;, y=\u0026quot;Frequency\u0026quot;) summ_graph  3. How are actions distributed and can you infer anything from that? Almost all sessions end at point 993  summ_tab \u0026lt;- page_log %\u0026gt;% group_by(tracking_id, session_id) %\u0026gt;% arrange(date) %\u0026gt;% mutate(seq= seq_along(session_id)) %\u0026gt;% filter(seq == max(seq)) %\u0026gt;% group_by(page_id,type) %\u0026gt;% summarise(count = length(unique(session_id)))%\u0026gt;% group_by(page_id) %\u0026gt;% mutate(perc = round((count/sum(count))*100,0)) %\u0026gt;% ungroup() %\u0026gt;% mutate(page_id = as.factor(page_id)) ## Print the table pr_func(summ_tab,cnames = c(\u0026quot;Page_ID\u0026quot;,\u0026quot;Type\u0026quot;, \u0026quot;Frequency\u0026quot;,\u0026quot;Percentage\u0026quot;))  {\"x\":{\"filter\":\"none\",\"extensions\":[\"Buttons\"],\"data\":[[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\"],[\"9003\",\"9003\",\"9005\",\"9006\",\"9006\",\"9007\",\"9020\",\"9020\"],[901,993,993,993,995,993,923,993],[1,9130,16288,32,1,2445,1,125094],[0,100,100,97,3,100,0,100]],\"container\":\"\\n \\n \\n  \\n Page_ID\\n Type\\n Frequency\\n Percentage\\n \\n \\n\",\"options\":{\"dom\":\"Bfrtip\",\"buttons\":[\"copy\",\"print\"],\"columnDefs\":[{\"className\":\"dt-right\",\"targets\":[2,3,4]},{\"orderable\":false,\"targets\":0}],\"order\":[],\"autoWidth\":false,\"orderClasses\":false}},\"evals\":[],\"jsHooks\":[]}  ## Graph summ_graph \u0026lt;- ggplot(summ_tab%\u0026gt;% filter(type == 993), aes(x=page_id,y=perc))+ geom_bar(stat = \u0026quot;identity\u0026quot;,fill = Company_XXX_yellow)+ geom_text(aes(label =perc),vjust = -0.25, size = 5)+ Company_XXX_theme+ labs(title = \u0026quot;Number of session ending with 993\\n per \\n Page ID\u0026quot;,x=\u0026quot;Page ID\u0026quot;, y=\u0026quot;Percentage\u0026quot;) summ_graph  4. What might be the action that we consider as a conversion? Is there a feasible way to verify that? \n  ","date":1566172800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1566172800,"objectID":"b5e5eee776d2b86b2c18a59faf6e2ed4","permalink":"/project/eb/","publishdate":"2019-08-19T00:00:00Z","relpermalink":"/project/eb/","section":"project","summary":"Company_XXX is an online company that meets the growing demand for independent travel information. it offers an extensive hotel meta search to travellers.","tags":["R"],"title":"Web Analytics","type":"project"},{"authors":null,"categories":null,"content":"","date":1564185600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564185600,"objectID":"5549885a6e457b9cbfcb1b54ef0532b1","permalink":"/project/dishonesty/","publishdate":"2019-07-27T00:00:00Z","relpermalink":"/project/dishonesty/","section":"project","summary":"And the measures which help to decrease lying.","tags":["R"],"title":"A game to measure honesty","type":"project"},{"authors":null,"categories":null,"content":"","date":1564185600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564185600,"objectID":"a6eb3d907acf6a4676c0ea9c476994cb","permalink":"/project/soiltesting/","publishdate":"2019-07-27T00:00:00Z","relpermalink":"/project/soiltesting/","section":"project","summary":"Data Analytics.","tags":["R"],"title":"Improving Soil testing among small holder farmers.","type":"project"},{"authors":null,"categories":null,"content":"","date":1564185600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564185600,"objectID":"a5c12346dbfe6fd9e595a3f9ff7efc5e","permalink":"/project/dignity/","publishdate":"2019-07-27T00:00:00Z","relpermalink":"/project/dignity/","section":"project","summary":"Is disrespectful treatment of participants a pressing problem in aid?.","tags":["R"],"title":"The benefits of development with dignity","type":"project"},{"authors":null,"categories":null,"content":"","date":1564185600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564185600,"objectID":"f90859d52f93d8987a7fe5071299d58f","permalink":"/project/humanaccount/","publishdate":"2019-07-27T00:00:00Z","relpermalink":"/project/humanaccount/","section":"project","summary":"Understanding customers in emerging markets, through a three-dimensional research framework that reveals the contextual, behavioral, and psychological dimensions of their financial lives.","tags":["R"],"title":"The Human Account","type":"project"},{"authors":null,"categories":null,"content":"","date":1564185600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564185600,"objectID":"edbefb7bb671e49a154c4f60c562e127","permalink":"/project/agents/","publishdate":"2019-07-27T00:00:00Z","relpermalink":"/project/agents/","section":"project","summary":"Incentives and Identity.","tags":["R"],"title":"Understanding agent networks","type":"project"},{"authors":null,"categories":["workshop","tidyverse"],"content":"  ","date":1562662800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1583832001,"objectID":"ab3105fc5007de628e4b47fa28969070","permalink":"/talk/user2019/","publishdate":"2020-03-10T00:00:00Z","relpermalink":"/talk/user2019/","section":"talk","summary":"  ","tags":null,"title":"AfricaR","type":"talk"},{"authors":null,"categories":["workshop","tidyverse"],"content":"  ","date":1559725200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1583832001,"objectID":"5a1b5dc07413d30489ce4035b51a4379","permalink":"/talk/dsa/","publishdate":"2020-03-10T00:00:00Z","relpermalink":"/talk/dsa/","section":"talk","summary":"  ","tags":null,"title":"Data Science Africa (DSA)","type":"talk"},{"authors":[""],"categories":null,"content":" Click the Slides button above to demo Academic\u0026rsquo;s Markdown slides feature.   Supplementary notes can be added here, including code and math.\n","date":1554595200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1554595200,"objectID":"557dc08fd4b672a0c08e0a8cf0c9ff7d","permalink":"/publication/preprint/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/preprint/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example preprint / working paper","type":"publication"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Academic  Academic | Documentation\n Features  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides   Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click  PDF Export: E   Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)   Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\n Fragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  Two  Three \n A fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears   Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view    Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links    night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links   Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/img/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}   Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }   Questions?  Ask\n Documentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Academic's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":["","Robert Ford"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Click the Slides button above to demo Academic\u0026rsquo;s Markdown slides feature.   Supplementary notes can be added here, including code and math.\n","date":1441065600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1441065600,"objectID":"966884cc0d8ac9e31fab966c4534e973","permalink":"/publication/journal-article/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/journal-article/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example journal article","type":"publication"},{"authors":["","Robert Ford"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Click the Slides button above to demo Academic\u0026rsquo;s Markdown slides feature.   Supplementary notes can be added here, including code and math.\n","date":1372636800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1372636800,"objectID":"69425fb10d4db090cfbd46854715582c","permalink":"/publication/conference-paper/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/conference-paper/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example conference paper","type":"publication"},{"authors":null,"categories":null,"content":"  Load the packages required Read in the wafanyikazi dataset 1. dplyr 1.1 select() 1.2 filter() 1.3 mutate() 1.3.1: mutate_all() 1.3.2: mutate_at() 1.3.3: mutate_if()  1.4 group_by() and summarise() 1.4.1 summarise() 1.4.2 summarise_at 1.4.3 summarise_if  1.5 arrange  2. tidyr 2.1 Wide to long 2.2 Long to wide  3. ggplot2 3.1 geom_bar of one variable 3.2 geom_bar of more than one variable 3.3 geom_line of one variable 3.4 geom_line of 2 variables 3.5 geom_boxplot of one variable 3.6 geom_boxplot of two variables 3.7 geom_area of one variable 3.8 geom_area of two variables 3.9 geom_histogram of one variable 3.10 geom_histogram of two variables    Tidyverse is a collection of R packages designed for data science. The packages that are included in tidyverse include:\n readr: Used for reading in datasets into R.\n dplyr: Used for data manipulation.\n tidyr: Used for cleaning messy datasets.\n ggplot2: Used for generating graphs.\n forcats: Used for manipulating factor variables in R.\n lubridate: Used for working with dates\n tibble: Creates simple dataframes.\n stringr: Used for manipulating strings.\n purrr: USed for functional programming.\n  Load the packages required #install.packages(\u0026quot;tidyverse\u0026quot;) library(tidyverse) library(rChambua)## Contains the dataset that we will use in this script (Wafanyikazi dataset) \n### 0.1 Install the libraries required ## Create a vector of packages to be installed pkgs \u0026lt;- c(\u0026quot;tidyverse\u0026quot;,\u0026quot;data.table\u0026quot;,\u0026quot;DT\u0026quot;,\u0026quot;lubridate\u0026quot;,\u0026quot;ggthemes\u0026quot;,\u0026quot;randomForest\u0026quot;,\u0026quot;readODS\u0026quot;,\u0026quot;ggcorrplot\u0026quot;) ## Check if there are packages you want to load, that are not already installed. miss_pkgs \u0026lt;- pkgs[!pkgs %in% installed.packages()[,1]] ## Installing the missing packages if(length(miss_pkgs)\u0026gt;0){ install.packages(miss_pkgs) } ## Loading all the packages invisible(lapply(pkgs,library,character.only=TRUE)) ## Remove the objects that are no longer required rm(miss_pkgs) rm(pkgs)  Read in the wafanyikazi dataset \n df \u0026lt;- wafanyikazi #df \u0026lt;- read_csv(\u0026quot;\u0026quot;)  1. dplyr Contains several functions, which we will look at one by one.\n1.1 select() Used for picking and dropping variables.  ## Picking variables. df1 \u0026lt;- df %\u0026gt;% select(Sid,Gender, Age) ## Dropping variables. ### When dopping variables, you insert a hyphen in front of the variable name. df1 \u0026lt;- df %\u0026gt;% select(-Sid, -Promotion) ## Picking or dropping variables acording to a given pattern. df1 \u0026lt;- df %\u0026gt;% select(contains(\u0026quot;f\u0026quot;)) ## Picking variables that contains letter e. df1 \u0026lt;- df %\u0026gt;% select(-ends_with(\u0026quot;t\u0026quot;)) ## Picking a sequence of variables that appear together. df1 \u0026lt;- df %\u0026gt;% select(Sid:Marital_Status) rm(df1)  1.2 filter() Used for picking values.\nfilter works with mathematical operators.\n == equality\n != non-equality\n \u0026lt; less than\n  greater than\n \u0026amp; and\n or  In english grammar, filter means removing unwanted material. But in R, we mostly use filter to keep observations, depending on the mathematical operators used.\n\n## Dropping obsevations based on the condition of a numeric variable. ### Let us drop all those who are aged 25 and above df2 \u0026lt;- df %\u0026gt;% filter(Age \u0026lt; 25) ## notice the number is not enclosed in quotes ### Let us keep all those who are older than 25, but younger than 40 df2 \u0026lt;- df %\u0026gt;% filter(Age \u0026gt;= 25 \u0026amp; Age \u0026lt;40) ## notice the number is not enclosed in quotes df2 \u0026lt;- df %\u0026gt;% filter(Age \u0026gt; 30 \u0026amp; Gender == \u0026quot;Female\u0026quot;) ## Dropping obsevations based on the condition of a character/factor variable. ### Let us drop all males df2 \u0026lt;- df %\u0026gt;% filter(Gender == \u0026quot;Female\u0026quot;) df2 \u0026lt;- df %\u0026gt;% filter(Gender != \u0026quot;Male\u0026quot;) rm(df2)  1.3 mutate() Used for generating variables\n ## Generating a basic variable. df3 \u0026lt;- df %\u0026gt;% mutate(prop_leavedays = Leave_Days/365) ## Generating a variable, based on the conditions of another variable. df3 \u0026lt;- df %\u0026gt;% mutate(Jinsia = if_else(Gender == \u0026quot;Female\u0026quot;,\u0026quot;Mke\u0026quot;,\u0026quot;Mme\u0026quot;)) rm(df3) There are other variations of mutate(). mutate_all(): Used for implementing the same function on all of the variables.\nmutate_at(): Used for implementing a function, for specific varibles. mutate_if(): Used for implementing a function, on specific variables, if they meet a certain condition.\n1.3.1: mutate_all() The syntax is written as mutate_all(~(function(.))). In the function, where a variable name should be inserted, replace that with a “period”, to signify all the variables. df4 \u0026lt;- df %\u0026gt;% mutate_all(~paste0(., \u0026quot;_x\u0026quot;)) df4 \u0026lt;- df %\u0026gt;% mutate_all(tolower) rm(df4)  1.3.2: mutate_at() The syntax is written as mutate_at(vars(), funs(.))\n\ndf4 \u0026lt;- df %\u0026gt;% mutate_at(vars(Gender, County), tolower) df4 \u0026lt;- df %\u0026gt;% mutate_at(vars(Gender, County), funs(paste(.,\u0026quot;x\u0026quot;))) rm(df4) \n 1.3.3: mutate_if() The syntax is written as mutate_if(condition, funs(.)) df4 \u0026lt;- df %\u0026gt;% mutate_if(is.numeric, funs(.*100)) df4 \u0026lt;- df %\u0026gt;% mutate_if(is.character, as.factor) rm(df4)   1.4 group_by() and summarise() Used for generating summary statistics. 1.4.1 summarise()  tab \u0026lt;- df %\u0026gt;% group_by(Gender) %\u0026gt;% count() %\u0026gt;% rename(Count = n) tab \u0026lt;- df %\u0026gt;% group_by(Gender) %\u0026gt;% summarise(Count = n()) tab \u0026lt;- df %\u0026gt;% group_by(Department) %\u0026gt;% summarise(Avg_Income = mean(Income, na.rm = T))   1.4.2 summarise_at \ntab \u0026lt;- df %\u0026gt;% group_by(County) %\u0026gt;% summarise_at(vars(Age, Leave_Days, Income), funs(mean(.,na.rm = TRUE)))   1.4.3 summarise_if \n tab \u0026lt;- df %\u0026gt;% group_by(County,Gender) %\u0026gt;% summarise_if(is.numeric, funs(mean(.,na.rm = TRUE)))   1.5 arrange Used for ordering the data based on certain variables  df6 \u0026lt;- df %\u0026gt;% arrange(Gender, Age) df6 \u0026lt;- df %\u0026gt;% arrange(Gender, desc(Age))   2. tidyr \n## Generatin a dummy dataset Year \u0026lt;- c(2010,2011,2012,2013,2014) Q1 \u0026lt;-c(1003,1532,954,841,823) Q2 \u0026lt;-c(1359,933,992,1434,1034) Q3 \u0026lt;-c(1326,904,845,1480,1184) Q4 \u0026lt;-c(1122,1479,889,1174,1317) sales = data.frame(Year,Q1 ,Q2, Q3, Q4) 2.1 Wide to long \n## Method 1: Using gather() sales1 \u0026lt;- sales %\u0026gt;% gather(\u0026quot;Quarters\u0026quot;,\u0026quot;Sales_Values\u0026quot;, -Year, na.rm = TRUE) ## Method 2: Using pivot_longer() sales2 \u0026lt;- sales %\u0026gt;% pivot_longer(-Year, names_to = \u0026quot;Quarters\u0026quot;, values_to = \u0026quot;Sales_Values\u0026quot;,values_drop_na = TRUE)  2.2 Long to wide \n ## Method 1: Using spread() sales3 \u0026lt;- sales1 %\u0026gt;% spread(Quarters, Sales_Values) ## Method 2: Using pivot_wider() sales4 \u0026lt;- sales2 %\u0026gt;% pivot_wider(names_from = \u0026quot;Quarters\u0026quot;, values_from = \u0026quot;Sales_Values\u0026quot;)   3. ggplot2 Used for creating beautiful graphs ## Let us create a theme that we will use in this training training_theme \u0026lt;- theme_hc()+ theme(legend.position = \u0026quot;right\u0026quot;, legend.direction = \u0026quot;vertical\u0026quot;, legend.title = element_blank(), plot.title = element_text( size = rel(1.6), hjust = 0.5), plot.subtitle = element_text(size = rel(1.5), hjust = 0.5), axis.text.x = element_text(size =rel(1.5),angle = 0), axis.text.y = element_text(size =rel(1.5),angle = 0), axis.title = element_text( size = rel(1.55)), axis.line.x = element_line(size = 1.5, colour = \u0026quot;black\u0026quot;), panel.background = element_rect(fill = NA)) rstudio_blue \u0026lt;- \u0026quot;#4AA4DE\u0026quot; 3.1 geom_bar of one variable \n ## Let us generate a graph that sows us the number of individuals per department. ## First come up with the table showing frequencies and percentages. tab \u0026lt;- df %\u0026gt;% group_by(Department) %\u0026gt;% count() %\u0026gt;% rename(Count = n) %\u0026gt;% ungroup() %\u0026gt;% mutate(Percentage = round(Count/ sum(Count) *100,1)) ## Generate the graph bargraph1 \u0026lt;- ggplot(data = tab, aes(x = Department, y = Percentage))+ geom_bar(stat = \u0026quot;identity\u0026quot;, fill = rstudio_blue)+ geom_text(aes(label = Percentage), vjust = -0.25, hjust = 0.5, size=4)+ training_theme+ labs(title = \u0026quot;Distribution of Respondents per Department\u0026quot;, x=\u0026quot;Department\u0026quot;, y=\u0026quot;Percentage\u0026quot;) bargraph1   3.2 geom_bar of more than one variable \n ## Let us generate a graph that sows us the number of individuals per department and gender category. ## First come up with the table showing frequencies and percentages. tab \u0026lt;- df %\u0026gt;% group_by(Department, Gender) %\u0026gt;% count() %\u0026gt;% rename(Count = n) %\u0026gt;% ungroup() %\u0026gt;% group_by(Department) %\u0026gt;% mutate(Percentage = round(Count/ sum(Count) *100,1)) ## Generate the graph bargraph2 \u0026lt;- ggplot(data = tab, aes(x = Department, y = Percentage, fill=Gender))+ geom_bar(stat = \u0026quot;identity\u0026quot;, position = \u0026quot;dodge\u0026quot;)+ geom_text(aes(label = Percentage), vjust = -0.25, hjust = 0.5, size=4,position = position_dodge(width = 0.9))+ training_theme+ scale_fill_brewer(palette = \u0026quot;Blues\u0026quot;)+ labs(title = \u0026quot;Distribution of Respondents per Department\u0026quot;, x=\u0026quot;Department\u0026quot;, y=\u0026quot;Percentage\u0026quot;) bargraph2   3.3 geom_line of one variable \n ## Let us generate a graph that sows us the average income per department. ## First come up with the table showing frequencies and percentages. tab \u0026lt;- df %\u0026gt;% group_by(Department) %\u0026gt;% summarise(avg_income = round(mean(Income, na.rm = T), 2)) ## Generate the graph linegraph1 \u0026lt;- ggplot(data = tab, aes(x = Department, y = avg_income, group = 1))+ geom_line(stat = \u0026quot;identity\u0026quot;, color = rstudio_blue)+ geom_text(aes(label = avg_income), vjust = -0.25, hjust = 0.5, size=4)+ training_theme+ labs(title = \u0026quot;Distribution of Average Income per Department\u0026quot;, x=\u0026quot;Department\u0026quot;, y=\u0026quot;Average Income\u0026quot;) linegraph1   3.4 geom_line of 2 variables \n ## Let us generate a graph that sows us the average income per department and gender. ## First come up with the table showing frequencies and percentages. tab \u0026lt;- df %\u0026gt;% group_by(Department, Gender) %\u0026gt;% summarise(avg_income = round(mean(Income, na.rm = T), 2)) ## Generate the graph linegraph2 \u0026lt;- ggplot(data = tab, aes(x = Department, y = avg_income, group = Gender, color = Gender))+ geom_line(stat = \u0026quot;identity\u0026quot;, size = 2)+ training_theme+ scale_color_manual(values = c(\u0026quot;Yellow\u0026quot;, \u0026quot;Red\u0026quot;))+ labs(title = \u0026quot;Distribution of Average Income per Department\u0026quot;, x=\u0026quot;Department\u0026quot;, y=\u0026quot;Average Income\u0026quot;) linegraph2   3.5 geom_boxplot of one variable \n ## Let us generate a graph that sows us the average income per department. ## Generate the graph boxplot1 \u0026lt;- ggplot(data = df, aes(x = Department, y = Income))+ geom_boxplot( fill = rstudio_blue)+ training_theme+ labs(title = \u0026quot;Distribution of Average Income per Department\u0026quot;, x=\u0026quot;Department\u0026quot;, y=\u0026quot;Average Income\u0026quot;) boxplot1   3.6 geom_boxplot of two variables \n ## Let us generate a graph that sows us the average income per department and gender. ## Generate the graph boxplot2 \u0026lt;- ggplot(data = df, aes(x = Department, y = Income, fill = Gender))+ geom_boxplot()+ training_theme+ scale_fill_brewer(palette = \u0026quot;Blues\u0026quot;)+ labs(title = \u0026quot;Distribution of Average Income per Department\u0026quot;, x=\u0026quot;Department\u0026quot;, y=\u0026quot;Average Income\u0026quot;) boxplot2   3.7 geom_area of one variable \n ## Let us generate a graph that sows us the average income per department and gender. ## Generate the graph area1 \u0026lt;- ggplot(data = df, aes(x = Income))+ geom_area(stat = \u0026quot;bin\u0026quot;, fill = rstudio_blue)+ training_theme+ labs(title = \u0026quot;Distribution of Average Income\u0026quot;, x=\u0026quot;Income\u0026quot;, y=\u0026quot;Count\u0026quot;) area1   3.8 geom_area of two variables \n ## Let us generate a graph that sows us the average income per department and gender. ## Generate the graph area2 \u0026lt;- ggplot(data = df, aes(x = Income, fill = Gender))+ geom_area(stat = \u0026quot;bin\u0026quot;)+ training_theme+ scale_fill_brewer(palette = \u0026quot;Blues\u0026quot;)+ labs(title = \u0026quot;Distribution of Average Income\u0026quot;, x=\u0026quot;Income\u0026quot;, y=\u0026quot;Count\u0026quot;) area2   3.9 geom_histogram of one variable \n ## Let us generate a graph that sows us the average income per department and gender. ## Generate the graph hist1 \u0026lt;- ggplot(data = df, aes(x = Income))+ geom_histogram(stat = \u0026quot;bin\u0026quot;, fill = rstudio_blue)+ training_theme+ labs(title = \u0026quot;Distribution of Average Income\u0026quot;, x=\u0026quot;Income\u0026quot;, y=\u0026quot;Count\u0026quot;) hist1   3.10 geom_histogram of two variables \n ## Let us generate a graph that sows us the average income per department and gender. ## Generate the graph hist2 \u0026lt;- ggplot(data = df, aes(x = Income, fill = Gender))+ geom_histogram(stat = \u0026quot;bin\u0026quot;)+ training_theme+ scale_fill_brewer(palette = \u0026quot;Blues\u0026quot;)+ labs(title = \u0026quot;Distribution of Average Income\u0026quot;, x=\u0026quot;Income\u0026quot;, y=\u0026quot;Count\u0026quot;) hist2    ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"47246a7949a778df6045fe4f28a8765e","permalink":"/codes/passa/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/codes/passa/","section":"codes","summary":"Load the packages required Read in the wafanyikazi dataset 1. dplyr 1.1 select() 1.2 filter() 1.3 mutate() 1.3.1: mutate_all() 1.3.2: mutate_at() 1.3.3: mutate_if()  1.4 group_by() and summarise() 1.","tags":["R"],"title":"Data Manipulation","type":"codes"}]